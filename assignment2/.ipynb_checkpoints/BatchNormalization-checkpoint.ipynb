{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "One way to make deep networks easier to train is to use more sophisticated optimization procedures such as SGD+momentum, RMSProp, or Adam. Another strategy is to change the architecture of the network to make it easier to train. One idea along these lines is batch normalization which was recently proposed by [3].\n",
    "\n",
    "The idea is relatively straightforward. Machine learning methods tend to work better when their input data consists of uncorrelated features with zero mean and unit variance. When training a neural network, we can preprocess the data before feeding it to the network to explicitly decorrelate its features; this will ensure that the first layer of the network sees data that follows a nice distribution. However even if we preprocess the input data, the activations at deeper layers of the network will likely no longer be decorrelated and will no longer have zero mean or unit variance since they are output from earlier layers in the network. Even worse, during the training process the distribution of features at each layer of the network will shift as the weights of each layer are updated.\n",
    "\n",
    "The authors of [3] hypothesize that the shifting distribution of features inside deep neural networks may make training deep networks more difficult. To overcome this problem, [3] proposes to insert batch normalization layers into the network. At training time, a batch normalization layer uses a minibatch of data to estimate the mean and standard deviation of each feature. These estimated means and standard deviations are then used to center and normalize the features of the minibatch. A running average of these means and standard deviations is kept during training, and at test time these running averages are used to center and normalize features.\n",
    "\n",
    "It is possible that this normalization strategy could reduce the representational power of the network, since it may sometimes be optimal for certain layers to have features that are not zero-mean or unit variance. To this end, the batch normalization layer includes learnable shift and scale parameters for each feature dimension.\n",
    "\n",
    "[3] Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing\n",
    "Internal Covariate Shift\", ICML 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization: Forward\n",
    "In the file `cs231n/layers.py`, implement the batch normalization forward pass in the function `batchnorm_forward`. Once you have done so, run the following to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before batch normalization:\n",
      "  means:  [ 51.11694344  22.48663268   6.75205258]\n",
      "  stds:  [ 35.16716108  39.29500106  29.87444502]\n",
      "After batch normalization (gamma=1, beta=0)\n",
      "  mean:  [  8.70414851e-16  -1.17128529e-16   9.88098492e-17]\n",
      "  std:  [ 1.  1.  1.]\n",
      "After batch normalization (nontrivial gamma, beta)\n",
      "  means:  [ 11.  12.  13.]\n",
      "  stds:  [ 1.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "# Check the training-time forward pass by checking means and variances\n",
    "# of features both before and after batch normalization\n",
    "\n",
    "# Simulate the forward pass for a two-layer network\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "X = np.random.randn(N, D1)\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "\n",
    "print 'Before batch normalization:'\n",
    "print '  means: ', a.mean(axis=0)\n",
    "print '  stds: ', a.std(axis=0)\n",
    "\n",
    "# Means should be close to zero and stds close to one\n",
    "print 'After batch normalization (gamma=1, beta=0)'\n",
    "a_norm, _ = batchnorm_forward(a, np.ones(D3), np.zeros(D3), {'mode': 'train'})\n",
    "print '  mean: ', a_norm.mean(axis=0)\n",
    "print '  std: ', a_norm.std(axis=0)\n",
    "\n",
    "# Now means should be close to beta and stds close to gamma\n",
    "gamma = np.asarray([1.0, 2.0, 3.0])\n",
    "beta = np.asarray([11.0, 12.0, 13.0])\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print 'After batch normalization (nontrivial gamma, beta)'\n",
    "print '  means: ', a_norm.mean(axis=0)\n",
    "print '  stds: ', a_norm.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After batch normalization (test-time):\n",
      "  means:  [ 0.01003161  0.08515161  0.04832938]\n",
      "  stds:  [ 0.98642755  1.01856759  1.04350799]\n"
     ]
    }
   ],
   "source": [
    "# Check the test-time forward pass by running the training-time\n",
    "# forward pass many times to warm up the running averages, and then\n",
    "# checking the means and variances of activations after a test-time\n",
    "# forward pass.\n",
    "\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(D3)\n",
    "beta = np.zeros(D3)\n",
    "for t in xrange(50):\n",
    "  X = np.random.randn(N, D1)\n",
    "  a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "  batchnorm_forward(a, gamma, beta, bn_param)\n",
    "bn_param['mode'] = 'test'\n",
    "X = np.random.randn(N, D1)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "# Means should be close to zero and stds close to one, but will be\n",
    "# noisier than training-time forward passes.\n",
    "print 'After batch normalization (test-time):'\n",
    "print '  means: ', a_norm.mean(axis=0)\n",
    "print '  stds: ', a_norm.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization: backward\n",
    "Now implement the backward pass for batch normalization in the function `batchnorm_backward`.\n",
    "\n",
    "To derive the backward pass you should write out the computation graph for batch normalization and backprop through each of the intermediate nodes. Some intermediates may have multiple outgoing branches; make sure to sum gradients across these branches in the backward pass.\n",
    "\n",
    "Once you have finished, run the following to numerically check your backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  1.01477115243e-07\n",
      "dgamma error:  9.34206227796e-12\n",
      "dbeta error:  4.74493593911e-12\n"
     ]
    }
   ],
   "source": [
    "# Gradient check batchnorm backward pass\n",
    "\n",
    "N, D = 4, 5\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fb = lambda b: batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "_, cache = batchnorm_forward(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = batchnorm_backward(dout, cache)\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dgamma error: ', rel_error(da_num, dgamma)\n",
    "print 'dbeta error: ', rel_error(db_num, dbeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization: alternative backward\n",
    "In class we talked about two different implementations for the sigmoid backward pass. One strategy is to write out a computation graph composed of simple operations and backprop through all intermediate values. Another strategy is to work out the derivatives on paper. For the sigmoid function, it turns out that you can derive a very simple formula for the backward pass by simplifying gradients on paper.\n",
    "\n",
    "Surprisingly, it turns out that you can also derive a simple expression for the batch normalization backward pass if you work out derivatives on paper and simplify. After doing so, implement the simplified batch normalization backward pass in the function `batchnorm_backward_alt` and compare the two implementations by running the following. Your two implementations should compute nearly identical results, but the alternative implementation should be a bit faster.\n",
    "\n",
    "NOTE: You can still complete the rest of the assignment if you don't figure this part out, so don't worry too much if you can't get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, D = 100, 500\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "out, cache = batchnorm_forward(x, gamma, beta, bn_param)\n",
    "\n",
    "t1 = time.time()\n",
    "dx1, dgamma1, dbeta1 = batchnorm_backward(dout, cache)\n",
    "t2 = time.time()\n",
    "dx2, dgamma2, dbeta2 = batchnorm_backward_alt(dout, cache)\n",
    "t3 = time.time()\n",
    "\n",
    "print 'dx difference: ', rel_error(dx1, dx2)\n",
    "print 'dgamma difference: ', rel_error(dgamma1, dgamma2)\n",
    "print 'dbeta difference: ', rel_error(dbeta1, dbeta2)\n",
    "print 'speedup: %.2fx' % ((t2 - t1) / (t3 - t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Nets with Batch Normalization\n",
    "Now that you have a working implementation for batch normalization, go back to your `FullyConnectedNet` in the file `cs2312n/classifiers/fc_net.py`. Modify your implementation to add batch normalization.\n",
    "\n",
    "Concretely, when the flag `use_batchnorm` is `True` in the constructor, you should insert a batch normalization layer before each ReLU nonlinearity. The outputs from the last layer of the network should not be normalized. Once you are done, run the following to gradient-check your implementation.\n",
    "\n",
    "HINT: You might find it useful to define an additional helper layer similar to those in the file `cs231n/layer_utils.py`. If you decide to do so, do it in the file `cs231n/classifiers/fc_net.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  2.43693493676\n",
      "(0, 0) 0.0\n",
      "(0, 1) 0.0\n",
      "(0, 2) 0.0\n",
      "(0, 3) 0.0\n",
      "(0, 4) 0.0\n",
      "(0, 5) 0.0\n",
      "(0, 6) 0.0\n",
      "(0, 7) 0.0\n",
      "(0, 8) 0.0\n",
      "(0, 9) 0.0\n",
      "(0, 10) 0.0\n",
      "(0, 11) 0.0\n",
      "(0, 12) 0.0\n",
      "(0, 13) 0.0\n",
      "(0, 14) 0.0\n",
      "(0, 15) 0.0\n",
      "(0, 16) 0.0\n",
      "(0, 17) 0.0\n",
      "(0, 18) 0.0\n",
      "(0, 19) 0.0\n",
      "(1, 0) 0.0\n",
      "(1, 1) 0.0\n",
      "(1, 2) 0.0\n",
      "(1, 3) 0.0\n",
      "(1, 4) 0.0\n",
      "(1, 5) 0.0\n",
      "(1, 6) 0.0\n",
      "(1, 7) 0.0\n",
      "(1, 8) 0.0\n",
      "(1, 9) 0.0\n",
      "(1, 10) 0.0\n",
      "(1, 11) 0.0\n",
      "(1, 12) 0.0\n",
      "(1, 13) 0.0\n",
      "(1, 14) 0.0\n",
      "(1, 15) 0.0\n",
      "(1, 16) 0.0\n",
      "(1, 17) 0.0\n",
      "(1, 18) 0.0\n",
      "(1, 19) 0.0\n",
      "(2, 0) 0.0\n",
      "(2, 1) 2.22044604925e-11\n",
      "(2, 2) 0.0\n",
      "(2, 3) 0.0\n",
      "(2, 4) 0.0\n",
      "(2, 5) 0.0\n",
      "(2, 6) 0.0\n",
      "(2, 7) 0.0\n",
      "(2, 8) 0.0\n",
      "(2, 9) 0.0\n",
      "(2, 10) 0.0\n",
      "(2, 11) 0.0\n",
      "(2, 12) 0.0\n",
      "(2, 13) 0.0\n",
      "(2, 14) 0.0\n",
      "(2, 15) 0.0\n",
      "(2, 16) 0.0\n",
      "(2, 17) 0.0\n",
      "(2, 18) 0.0\n",
      "(2, 19) 0.0\n",
      "(3, 0) 0.0\n",
      "(3, 1) 0.0\n",
      "(3, 2) 0.0\n",
      "(3, 3) 0.0\n",
      "(3, 4) 0.0\n",
      "(3, 5) 0.0\n",
      "(3, 6) 0.0\n",
      "(3, 7) 0.0\n",
      "(3, 8) 0.0\n",
      "(3, 9) 0.0\n",
      "(3, 10) 0.0\n",
      "(3, 11) 0.0\n",
      "(3, 12) 0.0\n",
      "(3, 13) 0.0\n",
      "(3, 14) 0.0\n",
      "(3, 15) 0.0\n",
      "(3, 16) 0.0\n",
      "(3, 17) 0.0\n",
      "(3, 18) 0.0\n",
      "(3, 19) 0.0\n",
      "(4, 0) 0.0\n",
      "(4, 1) 2.22044604925e-11\n",
      "(4, 2) 0.0\n",
      "(4, 3) 0.0\n",
      "(4, 4) 0.0\n",
      "(4, 5) 0.0\n",
      "(4, 6) 0.0\n",
      "(4, 7) 0.0\n",
      "(4, 8) 0.0\n",
      "(4, 9) 0.0\n",
      "(4, 10) 0.0\n",
      "(4, 11) 0.0\n",
      "(4, 12) 0.0\n",
      "(4, 13) 0.0\n",
      "(4, 14) 0.0\n",
      "(4, 15) 0.0\n",
      "(4, 16) 0.0\n",
      "(4, 17) 0.0\n",
      "(4, 18) 0.0\n",
      "(4, 19) 0.0\n",
      "(5, 0) 0.0\n",
      "(5, 1) 0.0\n",
      "(5, 2) 0.0\n",
      "(5, 3) 0.0\n",
      "(5, 4) 0.0\n",
      "(5, 5) 0.0\n",
      "(5, 6) 0.0\n",
      "(5, 7) 0.0\n",
      "(5, 8) 0.0\n",
      "(5, 9) 0.0\n",
      "(5, 10) 0.0\n",
      "(5, 11) 0.0\n",
      "(5, 12) 0.0\n",
      "(5, 13) 0.0\n",
      "(5, 14) 0.0\n",
      "(5, 15) 0.0\n",
      "(5, 16) 0.0\n",
      "(5, 17) 0.0\n",
      "(5, 18) 0.0\n",
      "(5, 19) -2.22044604925e-11\n",
      "(6, 0) 0.0\n",
      "(6, 1) 0.0\n",
      "(6, 2) 0.0\n",
      "(6, 3) 0.0\n",
      "(6, 4) 0.0\n",
      "(6, 5) 0.0\n",
      "(6, 6) 0.0\n",
      "(6, 7) 0.0\n",
      "(6, 8) 2.22044604925e-11\n",
      "(6, 9) 0.0\n",
      "(6, 10) 0.0\n",
      "(6, 11) 0.0\n",
      "(6, 12) 0.0\n",
      "(6, 13) 0.0\n",
      "(6, 14) 0.0\n",
      "(6, 15) 0.0\n",
      "(6, 16) 0.0\n",
      "(6, 17) 0.0\n",
      "(6, 18) 0.0\n",
      "(6, 19) 0.0\n",
      "(7, 0) 0.0\n",
      "(7, 1) 0.0\n",
      "(7, 2) 0.0\n",
      "(7, 3) 0.0\n",
      "(7, 4) 0.0\n",
      "(7, 5) 0.0\n",
      "(7, 6) 0.0\n",
      "(7, 7) 0.0\n",
      "(7, 8) -2.22044604925e-11\n",
      "(7, 9) 0.0\n",
      "(7, 10) 0.0\n",
      "(7, 11) 0.0\n",
      "(7, 12) 0.0\n",
      "(7, 13) 0.0\n",
      "(7, 14) 0.0\n",
      "(7, 15) 0.0\n",
      "(7, 16) 0.0\n",
      "(7, 17) 0.0\n",
      "(7, 18) 0.0\n",
      "(7, 19) -2.22044604925e-11\n",
      "(8, 0) 0.0\n",
      "(8, 1) 2.22044604925e-11\n",
      "(8, 2) 0.0\n",
      "(8, 3) 0.0\n",
      "(8, 4) 0.0\n",
      "(8, 5) 0.0\n",
      "(8, 6) 0.0\n",
      "(8, 7) 0.0\n",
      "(8, 8) 0.0\n",
      "(8, 9) 0.0\n",
      "(8, 10) 0.0\n",
      "(8, 11) 0.0\n",
      "(8, 12) 0.0\n",
      "(8, 13) 0.0\n",
      "(8, 14) 0.0\n",
      "(8, 15) 0.0\n",
      "(8, 16) 0.0\n",
      "(8, 17) 0.0\n",
      "(8, 18) 0.0\n",
      "(8, 19) 0.0\n",
      "(9, 0) 0.0\n",
      "(9, 1) 0.0\n",
      "(9, 2) 0.0\n",
      "(9, 3) 0.0\n",
      "(9, 4) 0.0\n",
      "(9, 5) 0.0\n",
      "(9, 6) 0.0\n",
      "(9, 7) 0.0\n",
      "(9, 8) 2.22044604925e-11\n",
      "(9, 9) 0.0\n",
      "(9, 10) 0.0\n",
      "(9, 11) 0.0\n",
      "(9, 12) 0.0\n",
      "(9, 13) 0.0\n",
      "(9, 14) 0.0\n",
      "(9, 15) 0.0\n",
      "(9, 16) 0.0\n",
      "(9, 17) 0.0\n",
      "(9, 18) 0.0\n",
      "(9, 19) 0.0\n",
      "(10, 0) 0.0\n",
      "(10, 1) 0.0\n",
      "(10, 2) 0.0\n",
      "(10, 3) 0.0\n",
      "(10, 4) 0.0\n",
      "(10, 5) 0.0\n",
      "(10, 6) 0.0\n",
      "(10, 7) 0.0\n",
      "(10, 8) 0.0\n",
      "(10, 9) 0.0\n",
      "(10, 10) 0.0\n",
      "(10, 11) 0.0\n",
      "(10, 12) 0.0\n",
      "(10, 13) 0.0\n",
      "(10, 14) 0.0\n",
      "(10, 15) 0.0\n",
      "(10, 16) 0.0\n",
      "(10, 17) 0.0\n",
      "(10, 18) 0.0\n",
      "(10, 19) 0.0\n",
      "(11, 0) 0.0\n",
      "(11, 1) 0.0\n",
      "(11, 2) 0.0\n",
      "(11, 3) 0.0\n",
      "(11, 4) 0.0\n",
      "(11, 5) 0.0\n",
      "(11, 6) 0.0\n",
      "(11, 7) 0.0\n",
      "(11, 8) 0.0\n",
      "(11, 9) 0.0\n",
      "(11, 10) 0.0\n",
      "(11, 11) 0.0\n",
      "(11, 12) 0.0\n",
      "(11, 13) 0.0\n",
      "(11, 14) 0.0\n",
      "(11, 15) 0.0\n",
      "(11, 16) 0.0\n",
      "(11, 17) 0.0\n",
      "(11, 18) 0.0\n",
      "(11, 19) 2.22044604925e-11\n",
      "(12, 0) 0.0\n",
      "(12, 1) 2.22044604925e-11\n",
      "(12, 2) 0.0\n",
      "(12, 3) 0.0\n",
      "(12, 4) 0.0\n",
      "(12, 5) 0.0\n",
      "(12, 6) 0.0\n",
      "(12, 7) 0.0\n",
      "(12, 8) 0.0\n",
      "(12, 9) 0.0\n",
      "(12, 10) 0.0\n",
      "(12, 11) 0.0\n",
      "(12, 12) 0.0\n",
      "(12, 13) 0.0\n",
      "(12, 14) 0.0\n",
      "(12, 15) 0.0\n",
      "(12, 16) 0.0\n",
      "(12, 17) 0.0\n",
      "(12, 18) 0.0\n",
      "(12, 19) 0.0\n",
      "(13, 0) 0.0\n",
      "(13, 1) 0.0\n",
      "(13, 2) 0.0\n",
      "(13, 3) 0.0\n",
      "(13, 4) 0.0\n",
      "(13, 5) 0.0\n",
      "(13, 6) 0.0\n",
      "(13, 7) 0.0\n",
      "(13, 8) 0.0\n",
      "(13, 9) 0.0\n",
      "(13, 10) 0.0\n",
      "(13, 11) 0.0\n",
      "(13, 12) 0.0\n",
      "(13, 13) 0.0\n",
      "(13, 14) 0.0\n",
      "(13, 15) 0.0\n",
      "(13, 16) 0.0\n",
      "(13, 17) 0.0\n",
      "(13, 18) 0.0\n",
      "(13, 19) 0.0\n",
      "(14, 0) 0.0\n",
      "(14, 1) 0.0\n",
      "(14, 2) 0.0\n",
      "(14, 3) 0.0\n",
      "(14, 4) 0.0\n",
      "(14, 5) 0.0\n",
      "(14, 6) 0.0\n",
      "(14, 7) 0.0\n",
      "(14, 8) 0.0\n",
      "(14, 9) -2.22044604925e-11\n",
      "(14, 10) 0.0\n",
      "(14, 11) 0.0\n",
      "(14, 12) 0.0\n",
      "(14, 13) 0.0\n",
      "(14, 14) 0.0\n",
      "(14, 15) 0.0\n",
      "(14, 16) 0.0\n",
      "(14, 17) 0.0\n",
      "(14, 18) 0.0\n",
      "(14, 19) -2.22044604925e-11\n",
      "W1 relative error: 1.00e+00\n",
      "(0, 0) 0.0\n",
      "(0, 1) 0.0\n",
      "(0, 2) 0.0\n",
      "(0, 3) 0.0\n",
      "(0, 4) 0.0\n",
      "(0, 5) 0.0\n",
      "(0, 6) 0.0\n",
      "(0, 7) 0.0\n",
      "(0, 8) 0.0\n",
      "(0, 9) 0.0\n",
      "(0, 10) 0.0\n",
      "(0, 11) 0.0\n",
      "(0, 12) 0.0\n",
      "(0, 13) 0.0\n",
      "(0, 14) 0.0\n",
      "(0, 15) 0.0\n",
      "(0, 16) 0.0\n",
      "(0, 17) 2.22044604925e-11\n",
      "(0, 18) 0.0\n",
      "(0, 19) 0.0\n",
      "(0, 20) 0.0\n",
      "(0, 21) 0.0\n",
      "(0, 22) 0.0\n",
      "(0, 23) 0.0\n",
      "(0, 24) 0.0\n",
      "(0, 25) 0.0\n",
      "(0, 26) 0.0\n",
      "(0, 27) 0.0\n",
      "(0, 28) 0.0\n",
      "(0, 29) 0.0\n",
      "(1, 0) 0.0\n",
      "(1, 1) 0.0\n",
      "(1, 2) 0.0\n",
      "(1, 3) 0.0\n",
      "(1, 4) 0.0\n",
      "(1, 5) 0.0\n",
      "(1, 6) 0.0\n",
      "(1, 7) 0.0\n",
      "(1, 8) 0.0\n",
      "(1, 9) 0.0\n",
      "(1, 10) 0.0\n",
      "(1, 11) 0.0\n",
      "(1, 12) 0.0\n",
      "(1, 13) 0.0\n",
      "(1, 14) 0.0\n",
      "(1, 15) 0.0\n",
      "(1, 16) 0.0\n",
      "(1, 17) 0.0\n",
      "(1, 18) 0.0\n",
      "(1, 19) 0.0\n",
      "(1, 20) 0.0\n",
      "(1, 21) 0.0\n",
      "(1, 22) 0.0\n",
      "(1, 23) 0.0\n",
      "(1, 24) 0.0\n",
      "(1, 25) 0.0\n",
      "(1, 26) 0.0\n",
      "(1, 27) 2.22044604925e-11\n",
      "(1, 28) 0.0\n",
      "(1, 29) 0.0\n",
      "(2, 0) 0.0\n",
      "(2, 1) 0.0\n",
      "(2, 2) 0.0\n",
      "(2, 3) 0.0\n",
      "(2, 4) 0.0\n",
      "(2, 5) 0.0\n",
      "(2, 6) 0.0\n",
      "(2, 7) 0.0\n",
      "(2, 8) 0.0\n",
      "(2, 9) 0.0\n",
      "(2, 10) 0.0\n",
      "(2, 11) 0.0\n",
      "(2, 12) 0.0\n",
      "(2, 13) 0.0\n",
      "(2, 14) 0.0\n",
      "(2, 15) 0.0\n",
      "(2, 16) 0.0\n",
      "(2, 17) 2.22044604925e-11\n",
      "(2, 18) 0.0\n",
      "(2, 19) 0.0\n",
      "(2, 20) 0.0\n",
      "(2, 21) 0.0\n",
      "(2, 22) 0.0\n",
      "(2, 23) 0.0\n",
      "(2, 24) 0.0\n",
      "(2, 25) 0.0\n",
      "(2, 26) 0.0\n",
      "(2, 27) 0.0\n",
      "(2, 28) 0.0\n",
      "(2, 29) 0.0\n",
      "(3, 0) 0.0\n",
      "(3, 1) 0.0\n",
      "(3, 2) 0.0\n",
      "(3, 3) 0.0\n",
      "(3, 4) 0.0\n",
      "(3, 5) 0.0\n",
      "(3, 6) 0.0\n",
      "(3, 7) 0.0\n",
      "(3, 8) 0.0\n",
      "(3, 9) 0.0\n",
      "(3, 10) 0.0\n",
      "(3, 11) 0.0\n",
      "(3, 12) 0.0\n",
      "(3, 13) 0.0\n",
      "(3, 14) 0.0\n",
      "(3, 15) 0.0\n",
      "(3, 16) 0.0\n",
      "(3, 17) -2.22044604925e-11\n",
      "(3, 18) 0.0\n",
      "(3, 19) 0.0\n",
      "(3, 20) 0.0\n",
      "(3, 21) 0.0\n",
      "(3, 22) 0.0\n",
      "(3, 23) 0.0\n",
      "(3, 24) 0.0\n",
      "(3, 25) 0.0\n",
      "(3, 26) 0.0\n",
      "(3, 27) 2.22044604925e-11\n",
      "(3, 28) 0.0\n",
      "(3, 29) 0.0\n",
      "(4, 0) 0.0\n",
      "(4, 1) 0.0\n",
      "(4, 2) 0.0\n",
      "(4, 3) 0.0\n",
      "(4, 4) 0.0\n",
      "(4, 5) 0.0\n",
      "(4, 6) 0.0\n",
      "(4, 7) 0.0\n",
      "(4, 8) 0.0\n",
      "(4, 9) 0.0\n",
      "(4, 10) 0.0\n",
      "(4, 11) 0.0\n",
      "(4, 12) 0.0\n",
      "(4, 13) 0.0\n",
      "(4, 14) 0.0\n",
      "(4, 15) 0.0\n",
      "(4, 16) 0.0\n",
      "(4, 17) 2.22044604925e-11\n",
      "(4, 18) 0.0\n",
      "(4, 19) 0.0\n",
      "(4, 20) 0.0\n",
      "(4, 21) 0.0\n",
      "(4, 22) 0.0\n",
      "(4, 23) 0.0\n",
      "(4, 24) 0.0\n",
      "(4, 25) 0.0\n",
      "(4, 26) 0.0\n",
      "(4, 27) 0.0\n",
      "(4, 28) 2.22044604925e-11\n",
      "(4, 29) 0.0\n",
      "(5, 0) 0.0\n",
      "(5, 1) 0.0\n",
      "(5, 2) 0.0\n",
      "(5, 3) 0.0\n",
      "(5, 4) 0.0\n",
      "(5, 5) 0.0\n",
      "(5, 6) 0.0\n",
      "(5, 7) 0.0\n",
      "(5, 8) 0.0\n",
      "(5, 9) 0.0\n",
      "(5, 10) 0.0\n",
      "(5, 11) 0.0\n",
      "(5, 12) 0.0\n",
      "(5, 13) 0.0\n",
      "(5, 14) 0.0\n",
      "(5, 15) 0.0\n",
      "(5, 16) 0.0\n",
      "(5, 17) 0.0\n",
      "(5, 18) 0.0\n",
      "(5, 19) 0.0\n",
      "(5, 20) 0.0\n",
      "(5, 21) 0.0\n",
      "(5, 22) 0.0\n",
      "(5, 23) 0.0\n",
      "(5, 24) 0.0\n",
      "(5, 25) 0.0\n",
      "(5, 26) 0.0\n",
      "(5, 27) 0.0\n",
      "(5, 28) 0.0\n",
      "(5, 29) 0.0\n",
      "(6, 0) 0.0\n",
      "(6, 1) 0.0\n",
      "(6, 2) 0.0\n",
      "(6, 3) 0.0\n",
      "(6, 4) 0.0\n",
      "(6, 5) 0.0\n",
      "(6, 6) 0.0\n",
      "(6, 7) 2.22044604925e-11\n",
      "(6, 8) 0.0\n",
      "(6, 9) 0.0\n",
      "(6, 10) 0.0\n",
      "(6, 11) 0.0\n",
      "(6, 12) 0.0\n",
      "(6, 13) 0.0\n",
      "(6, 14) 0.0\n",
      "(6, 15) 0.0\n",
      "(6, 16) 0.0\n",
      "(6, 17) -2.22044604925e-11\n",
      "(6, 18) 0.0\n",
      "(6, 19) 0.0\n",
      "(6, 20) 0.0\n",
      "(6, 21) 0.0\n",
      "(6, 22) 0.0\n",
      "(6, 23) 0.0\n",
      "(6, 24) 0.0\n",
      "(6, 25) 0.0\n",
      "(6, 26) 0.0\n",
      "(6, 27) 0.0\n",
      "(6, 28) 0.0\n",
      "(6, 29) 0.0\n",
      "(7, 0) 0.0\n",
      "(7, 1) 0.0\n",
      "(7, 2) 0.0\n",
      "(7, 3) 0.0\n",
      "(7, 4) 0.0\n",
      "(7, 5) 0.0\n",
      "(7, 6) 0.0\n",
      "(7, 7) 0.0\n",
      "(7, 8) 0.0\n",
      "(7, 9) 0.0\n",
      "(7, 10) 0.0\n",
      "(7, 11) 0.0\n",
      "(7, 12) 0.0\n",
      "(7, 13) 0.0\n",
      "(7, 14) 0.0\n",
      "(7, 15) 0.0\n",
      "(7, 16) 0.0\n",
      "(7, 17) -2.22044604925e-11\n",
      "(7, 18) 0.0\n",
      "(7, 19) 0.0\n",
      "(7, 20) 0.0\n",
      "(7, 21) 0.0\n",
      "(7, 22) 0.0\n",
      "(7, 23) 0.0\n",
      "(7, 24) 0.0\n",
      "(7, 25) 0.0\n",
      "(7, 26) 0.0\n",
      "(7, 27) 2.22044604925e-11\n",
      "(7, 28) 0.0\n",
      "(7, 29) 0.0\n",
      "(8, 0) 0.0\n",
      "(8, 1) 0.0\n",
      "(8, 2) 0.0\n",
      "(8, 3) 0.0\n",
      "(8, 4) 0.0\n",
      "(8, 5) 0.0\n",
      "(8, 6) 0.0\n",
      "(8, 7) 0.0\n",
      "(8, 8) 0.0\n",
      "(8, 9) 0.0\n",
      "(8, 10) 0.0\n",
      "(8, 11) 0.0\n",
      "(8, 12) 0.0\n",
      "(8, 13) 0.0\n",
      "(8, 14) 0.0\n",
      "(8, 15) 0.0\n",
      "(8, 16) 0.0\n",
      "(8, 17) 2.22044604925e-11\n",
      "(8, 18) 0.0\n",
      "(8, 19) 0.0\n",
      "(8, 20) 0.0\n",
      "(8, 21) 0.0\n",
      "(8, 22) 0.0\n",
      "(8, 23) 0.0\n",
      "(8, 24) 0.0\n",
      "(8, 25) 0.0\n",
      "(8, 26) 0.0\n",
      "(8, 27) 0.0\n",
      "(8, 28) 0.0\n",
      "(8, 29) 0.0\n",
      "(9, 0) 0.0\n",
      "(9, 1) 0.0\n",
      "(9, 2) 0.0\n",
      "(9, 3) 0.0\n",
      "(9, 4) 0.0\n",
      "(9, 5) 0.0\n",
      "(9, 6) 0.0\n",
      "(9, 7) 2.22044604925e-11\n",
      "(9, 8) 0.0\n",
      "(9, 9) 0.0\n",
      "(9, 10) 0.0\n",
      "(9, 11) 0.0\n",
      "(9, 12) 0.0\n",
      "(9, 13) 0.0\n",
      "(9, 14) 0.0\n",
      "(9, 15) 0.0\n",
      "(9, 16) 0.0\n",
      "(9, 17) -2.22044604925e-11\n",
      "(9, 18) 0.0\n",
      "(9, 19) 0.0\n",
      "(9, 20) 0.0\n",
      "(9, 21) 0.0\n",
      "(9, 22) 0.0\n",
      "(9, 23) 0.0\n",
      "(9, 24) 0.0\n",
      "(9, 25) 0.0\n",
      "(9, 26) 0.0\n",
      "(9, 27) 2.22044604925e-11\n",
      "(9, 28) 0.0\n",
      "(9, 29) 0.0\n",
      "(10, 0) 0.0\n",
      "(10, 1) 0.0\n",
      "(10, 2) 0.0\n",
      "(10, 3) 0.0\n",
      "(10, 4) 0.0\n",
      "(10, 5) 0.0\n",
      "(10, 6) 0.0\n",
      "(10, 7) 2.22044604925e-11\n",
      "(10, 8) 0.0\n",
      "(10, 9) 0.0\n",
      "(10, 10) 0.0\n",
      "(10, 11) 0.0\n",
      "(10, 12) 0.0\n",
      "(10, 13) 0.0\n",
      "(10, 14) 0.0\n",
      "(10, 15) 0.0\n",
      "(10, 16) 0.0\n",
      "(10, 17) -2.22044604925e-11\n",
      "(10, 18) 0.0\n",
      "(10, 19) 0.0\n",
      "(10, 20) 0.0\n",
      "(10, 21) 0.0\n",
      "(10, 22) 0.0\n",
      "(10, 23) 0.0\n",
      "(10, 24) 0.0\n",
      "(10, 25) 0.0\n",
      "(10, 26) 0.0\n",
      "(10, 27) 0.0\n",
      "(10, 28) 0.0\n",
      "(10, 29) 0.0\n",
      "(11, 0) 0.0\n",
      "(11, 1) 0.0\n",
      "(11, 2) 0.0\n",
      "(11, 3) 0.0\n",
      "(11, 4) 0.0\n",
      "(11, 5) 0.0\n",
      "(11, 6) 0.0\n",
      "(11, 7) 0.0\n",
      "(11, 8) 0.0\n",
      "(11, 9) 0.0\n",
      "(11, 10) 0.0\n",
      "(11, 11) 0.0\n",
      "(11, 12) 0.0\n",
      "(11, 13) 0.0\n",
      "(11, 14) 0.0\n",
      "(11, 15) 0.0\n",
      "(11, 16) 0.0\n",
      "(11, 17) 0.0\n",
      "(11, 18) 0.0\n",
      "(11, 19) 0.0\n",
      "(11, 20) 0.0\n",
      "(11, 21) 0.0\n",
      "(11, 22) 0.0\n",
      "(11, 23) 0.0\n",
      "(11, 24) 0.0\n",
      "(11, 25) 0.0\n",
      "(11, 26) 0.0\n",
      "(11, 27) 0.0\n",
      "(11, 28) 0.0\n",
      "(11, 29) 0.0\n",
      "(12, 0) 0.0\n",
      "(12, 1) 0.0\n",
      "(12, 2) 0.0\n",
      "(12, 3) 0.0\n",
      "(12, 4) 0.0\n",
      "(12, 5) 0.0\n",
      "(12, 6) 0.0\n",
      "(12, 7) 2.22044604925e-11\n",
      "(12, 8) 0.0\n",
      "(12, 9) 0.0\n",
      "(12, 10) 0.0\n",
      "(12, 11) 0.0\n",
      "(12, 12) 0.0\n",
      "(12, 13) 0.0\n",
      "(12, 14) 0.0\n",
      "(12, 15) 0.0\n",
      "(12, 16) 0.0\n",
      "(12, 17) 0.0\n",
      "(12, 18) 0.0\n",
      "(12, 19) 0.0\n",
      "(12, 20) 0.0\n",
      "(12, 21) 0.0\n",
      "(12, 22) 0.0\n",
      "(12, 23) 0.0\n",
      "(12, 24) 0.0\n",
      "(12, 25) 0.0\n",
      "(12, 26) 0.0\n",
      "(12, 27) 0.0\n",
      "(12, 28) 2.22044604925e-11\n",
      "(12, 29) 0.0\n",
      "(13, 0) 0.0\n",
      "(13, 1) 0.0\n",
      "(13, 2) 0.0\n",
      "(13, 3) 0.0\n",
      "(13, 4) 0.0\n",
      "(13, 5) 0.0\n",
      "(13, 6) 0.0\n",
      "(13, 7) 0.0\n",
      "(13, 8) 0.0\n",
      "(13, 9) 0.0\n",
      "(13, 10) 0.0\n",
      "(13, 11) 0.0\n",
      "(13, 12) 0.0\n",
      "(13, 13) 0.0\n",
      "(13, 14) 0.0\n",
      "(13, 15) 0.0\n",
      "(13, 16) 0.0\n",
      "(13, 17) 0.0\n",
      "(13, 18) 0.0\n",
      "(13, 19) 0.0\n",
      "(13, 20) 0.0\n",
      "(13, 21) 0.0\n",
      "(13, 22) 0.0\n",
      "(13, 23) 0.0\n",
      "(13, 24) 0.0\n",
      "(13, 25) 0.0\n",
      "(13, 26) 0.0\n",
      "(13, 27) 0.0\n",
      "(13, 28) 0.0\n",
      "(13, 29) 0.0\n",
      "(14, 0) 0.0\n",
      "(14, 1) 0.0\n",
      "(14, 2) 0.0\n",
      "(14, 3) 0.0\n",
      "(14, 4) 0.0\n",
      "(14, 5) 0.0\n",
      "(14, 6) 0.0\n",
      "(14, 7) 2.22044604925e-11\n",
      "(14, 8) 0.0\n",
      "(14, 9) 0.0\n",
      "(14, 10) 0.0\n",
      "(14, 11) 0.0\n",
      "(14, 12) 0.0\n",
      "(14, 13) 0.0\n",
      "(14, 14) 0.0\n",
      "(14, 15) 0.0\n",
      "(14, 16) 0.0\n",
      "(14, 17) 0.0\n",
      "(14, 18) 0.0\n",
      "(14, 19) 0.0\n",
      "(14, 20) 0.0\n",
      "(14, 21) 0.0\n",
      "(14, 22) 0.0\n",
      "(14, 23) 0.0\n",
      "(14, 24) 0.0\n",
      "(14, 25) 0.0\n",
      "(14, 26) 0.0\n",
      "(14, 27) 0.0\n",
      "(14, 28) 2.22044604925e-11\n",
      "(14, 29) 0.0\n",
      "(15, 0) 0.0\n",
      "(15, 1) 0.0\n",
      "(15, 2) 0.0\n",
      "(15, 3) 0.0\n",
      "(15, 4) 0.0\n",
      "(15, 5) 0.0\n",
      "(15, 6) 0.0\n",
      "(15, 7) 0.0\n",
      "(15, 8) 0.0\n",
      "(15, 9) 0.0\n",
      "(15, 10) 0.0\n",
      "(15, 11) 0.0\n",
      "(15, 12) 0.0\n",
      "(15, 13) 0.0\n",
      "(15, 14) 0.0\n",
      "(15, 15) 0.0\n",
      "(15, 16) 0.0\n",
      "(15, 17) 0.0\n",
      "(15, 18) 0.0\n",
      "(15, 19) 0.0\n",
      "(15, 20) 0.0\n",
      "(15, 21) 0.0\n",
      "(15, 22) 0.0\n",
      "(15, 23) 0.0\n",
      "(15, 24) 0.0\n",
      "(15, 25) 0.0\n",
      "(15, 26) 0.0\n",
      "(15, 27) 0.0\n",
      "(15, 28) 0.0\n",
      "(15, 29) 0.0\n",
      "(16, 0) 0.0\n",
      "(16, 1) 0.0\n",
      "(16, 2) 0.0\n",
      "(16, 3) 0.0\n",
      "(16, 4) 0.0\n",
      "(16, 5) 0.0\n",
      "(16, 6) 0.0\n",
      "(16, 7) 0.0\n",
      "(16, 8) 0.0\n",
      "(16, 9) 0.0\n",
      "(16, 10) 0.0\n",
      "(16, 11) 0.0\n",
      "(16, 12) 0.0\n",
      "(16, 13) 0.0\n",
      "(16, 14) 0.0\n",
      "(16, 15) 0.0\n",
      "(16, 16) 0.0\n",
      "(16, 17) 2.22044604925e-11\n",
      "(16, 18) 0.0\n",
      "(16, 19) 0.0\n",
      "(16, 20) 0.0\n",
      "(16, 21) 0.0\n",
      "(16, 22) 0.0\n",
      "(16, 23) 0.0\n",
      "(16, 24) 0.0\n",
      "(16, 25) 0.0\n",
      "(16, 26) 0.0\n",
      "(16, 27) 0.0\n",
      "(16, 28) 0.0\n",
      "(16, 29) 0.0\n",
      "(17, 0) 0.0\n",
      "(17, 1) 0.0\n",
      "(17, 2) 0.0\n",
      "(17, 3) 0.0\n",
      "(17, 4) 0.0\n",
      "(17, 5) 0.0\n",
      "(17, 6) 0.0\n",
      "(17, 7) 0.0\n",
      "(17, 8) 0.0\n",
      "(17, 9) 0.0\n",
      "(17, 10) 0.0\n",
      "(17, 11) 0.0\n",
      "(17, 12) 0.0\n",
      "(17, 13) 0.0\n",
      "(17, 14) 0.0\n",
      "(17, 15) 0.0\n",
      "(17, 16) 0.0\n",
      "(17, 17) 0.0\n",
      "(17, 18) 0.0\n",
      "(17, 19) 0.0\n",
      "(17, 20) 0.0\n",
      "(17, 21) 0.0\n",
      "(17, 22) 0.0\n",
      "(17, 23) 0.0\n",
      "(17, 24) 0.0\n",
      "(17, 25) 0.0\n",
      "(17, 26) 0.0\n",
      "(17, 27) 0.0\n",
      "(17, 28) 0.0\n",
      "(17, 29) 0.0\n",
      "(18, 0) 0.0\n",
      "(18, 1) 0.0\n",
      "(18, 2) 0.0\n",
      "(18, 3) 0.0\n",
      "(18, 4) 0.0\n",
      "(18, 5) 0.0\n",
      "(18, 6) 0.0\n",
      "(18, 7) 2.22044604925e-11\n",
      "(18, 8) 0.0\n",
      "(18, 9) 0.0\n",
      "(18, 10) 0.0\n",
      "(18, 11) 0.0\n",
      "(18, 12) 0.0\n",
      "(18, 13) 0.0\n",
      "(18, 14) 0.0\n",
      "(18, 15) 0.0\n",
      "(18, 16) 0.0\n",
      "(18, 17) 0.0\n",
      "(18, 18) 0.0\n",
      "(18, 19) 0.0\n",
      "(18, 20) 0.0\n",
      "(18, 21) 0.0\n",
      "(18, 22) 0.0\n",
      "(18, 23) 0.0\n",
      "(18, 24) 0.0\n",
      "(18, 25) 0.0\n",
      "(18, 26) 0.0\n",
      "(18, 27) 0.0\n",
      "(18, 28) 2.22044604925e-11\n",
      "(18, 29) 0.0\n",
      "(19, 0) 0.0\n",
      "(19, 1) 0.0\n",
      "(19, 2) 0.0\n",
      "(19, 3) 0.0\n",
      "(19, 4) 0.0\n",
      "(19, 5) 0.0\n",
      "(19, 6) 0.0\n",
      "(19, 7) 0.0\n",
      "(19, 8) 0.0\n",
      "(19, 9) 0.0\n",
      "(19, 10) 0.0\n",
      "(19, 11) 0.0\n",
      "(19, 12) 0.0\n",
      "(19, 13) 0.0\n",
      "(19, 14) 0.0\n",
      "(19, 15) 0.0\n",
      "(19, 16) 0.0\n",
      "(19, 17) 0.0\n",
      "(19, 18) 0.0\n",
      "(19, 19) 0.0\n",
      "(19, 20) 0.0\n",
      "(19, 21) 0.0\n",
      "(19, 22) 0.0\n",
      "(19, 23) 0.0\n",
      "(19, 24) 0.0\n",
      "(19, 25) 0.0\n",
      "(19, 26) 0.0\n",
      "(19, 27) 0.0\n",
      "(19, 28) 0.0\n",
      "(19, 29) 0.0\n",
      "W2 relative error: 1.00e+00\n",
      "(0, 0) 0.0383065224874\n",
      "(0, 1) 0.0447193933439\n",
      "(0, 2) 0.0517930485611\n",
      "(0, 3) 0.0709617545613\n",
      "(0, 4) 0.0539246929776\n",
      "(0, 5) -0.455575867986\n",
      "(0, 6) 0.0592012489697\n",
      "(0, 7) 0.0606784608337\n",
      "(0, 8) 0.0389547477164\n",
      "(0, 9) 0.0370359985569\n",
      "(1, 0) -0.456984372188\n",
      "(1, 1) 0.0521591528413\n",
      "(1, 2) 0.0381703908037\n",
      "(1, 3) 0.0435148225231\n",
      "(1, 4) 0.0470272903508\n",
      "(1, 5) 0.0531966916073\n",
      "(1, 6) 0.0427774009104\n",
      "(1, 7) 0.0593292147633\n",
      "(1, 8) 0.0675705036368\n",
      "(1, 9) 0.0532389047736\n",
      "(2, 0) -0.456984372166\n",
      "(2, 1) 0.0521591528413\n",
      "(2, 2) 0.0381703908037\n",
      "(2, 3) 0.0435148225231\n",
      "(2, 4) 0.0470272903508\n",
      "(2, 5) 0.0531966916073\n",
      "(2, 6) 0.0427774009104\n",
      "(2, 7) 0.0593292147633\n",
      "(2, 8) 0.0675705036368\n",
      "(2, 9) 0.0532389047736\n",
      "(3, 0) 0.0383065224874\n",
      "(3, 1) 0.0447193933439\n",
      "(3, 2) 0.0517930485611\n",
      "(3, 3) 0.0709617545613\n",
      "(3, 4) 0.0539246929776\n",
      "(3, 5) -0.455575867986\n",
      "(3, 6) 0.0592012489697\n",
      "(3, 7) 0.0606784608337\n",
      "(3, 8) 0.0389547477164\n",
      "(3, 9) 0.0370359985569\n",
      "(4, 0) 0.0383065224874\n",
      "(4, 1) 0.0447193933439\n",
      "(4, 2) 0.0517930485611\n",
      "(4, 3) 0.0709617545613\n",
      "(4, 4) 0.0539246929776\n",
      "(4, 5) -0.455575867986\n",
      "(4, 6) 0.0592012489697\n",
      "(4, 7) 0.0606784608337\n",
      "(4, 8) 0.0389547477164\n",
      "(4, 9) 0.0370359985569\n",
      "(5, 0) -0.456984372188\n",
      "(5, 1) 0.0521591528413\n",
      "(5, 2) 0.0381703908037\n",
      "(5, 3) 0.0435148225231\n",
      "(5, 4) 0.0470272903508\n",
      "(5, 5) 0.0531966916073\n",
      "(5, 6) 0.0427774009104\n",
      "(5, 7) 0.0593292147633\n",
      "(5, 8) 0.0675705036368\n",
      "(5, 9) 0.0532389047736\n",
      "(6, 0) -0.456984372166\n",
      "(6, 1) 0.0521591528413\n",
      "(6, 2) 0.0381703908037\n",
      "(6, 3) 0.0435148225231\n",
      "(6, 4) 0.0470272903508\n",
      "(6, 5) 0.0531966916073\n",
      "(6, 6) 0.0427774009104\n",
      "(6, 7) 0.0593292147633\n",
      "(6, 8) 0.0675705036368\n",
      "(6, 9) 0.0532389047736\n",
      "(7, 0) -0.456984372188\n",
      "(7, 1) 0.0521591528413\n",
      "(7, 2) 0.0381703908037\n",
      "(7, 3) 0.0435148225231\n",
      "(7, 4) 0.0470272903508\n",
      "(7, 5) 0.0531966916073\n",
      "(7, 6) 0.0427774009104\n",
      "(7, 7) 0.0593292147633\n",
      "(7, 8) 0.0675705036368\n",
      "(7, 9) 0.0532389047736\n",
      "(8, 0) 0.0383065224874\n",
      "(8, 1) 0.0447193933439\n",
      "(8, 2) 0.0517930485611\n",
      "(8, 3) 0.0709617545613\n",
      "(8, 4) 0.0539246929776\n",
      "(8, 5) -0.455575867986\n",
      "(8, 6) 0.0592012489697\n",
      "(8, 7) 0.0606784608337\n",
      "(8, 8) 0.0389547477164\n",
      "(8, 9) 0.0370359985569\n",
      "(9, 0) -0.456984372188\n",
      "(9, 1) 0.0521591528413\n",
      "(9, 2) 0.0381703908037\n",
      "(9, 3) 0.0435148225231\n",
      "(9, 4) 0.0470272903508\n",
      "(9, 5) 0.0531966916073\n",
      "(9, 6) 0.0427774009104\n",
      "(9, 7) 0.0593292147633\n",
      "(9, 8) 0.0675705036368\n",
      "(9, 9) 0.0532389047736\n",
      "(10, 0) 0.0383065224874\n",
      "(10, 1) 0.0447193933439\n",
      "(10, 2) 0.0517930485611\n",
      "(10, 3) 0.0709617545613\n",
      "(10, 4) 0.0539246929776\n",
      "(10, 5) -0.455575867986\n",
      "(10, 6) 0.0592012489697\n",
      "(10, 7) 0.0606784608337\n",
      "(10, 8) 0.0389547477164\n",
      "(10, 9) 0.0370359985569\n",
      "(11, 0) 0.0383065224874\n",
      "(11, 1) 0.0447193933439\n",
      "(11, 2) 0.0517930485611\n",
      "(11, 3) 0.0709617545613\n",
      "(11, 4) 0.0539246929776\n",
      "(11, 5) -0.455575867986\n",
      "(11, 6) 0.0592012489697\n",
      "(11, 7) 0.0606784608337\n",
      "(11, 8) 0.0389547477164\n",
      "(11, 9) 0.0370359985569\n",
      "(12, 0) -0.456984372166\n",
      "(12, 1) 0.0521591528413\n",
      "(12, 2) 0.0381703908037\n",
      "(12, 3) 0.0435148225231\n",
      "(12, 4) 0.0470272903508\n",
      "(12, 5) 0.0531966916073\n",
      "(12, 6) 0.0427774009104\n",
      "(12, 7) 0.0593292147633\n",
      "(12, 8) 0.0675705036368\n",
      "(12, 9) 0.0532389047736\n",
      "(13, 0) 0.0383065224874\n",
      "(13, 1) 0.0447193933439\n",
      "(13, 2) 0.0517930485611\n",
      "(13, 3) 0.0709617545613\n",
      "(13, 4) 0.0539246929776\n",
      "(13, 5) -0.455575867986\n",
      "(13, 6) 0.0592012489697\n",
      "(13, 7) 0.0606784608337\n",
      "(13, 8) 0.0389547477164\n",
      "(13, 9) 0.0370359985569\n",
      "(14, 0) -0.456984372166\n",
      "(14, 1) 0.0521591528413\n",
      "(14, 2) 0.0381703908037\n",
      "(14, 3) 0.0435148225231\n",
      "(14, 4) 0.0470272903508\n",
      "(14, 5) 0.0531966916073\n",
      "(14, 6) 0.0427774009104\n",
      "(14, 7) 0.0593292147633\n",
      "(14, 8) 0.0675705036368\n",
      "(14, 9) 0.0532389047736\n",
      "(15, 0) -0.456984372188\n",
      "(15, 1) 0.0521591528413\n",
      "(15, 2) 0.0381703908037\n",
      "(15, 3) 0.0435148225231\n",
      "(15, 4) 0.0470272903508\n",
      "(15, 5) 0.0531966916073\n",
      "(15, 6) 0.0427774009104\n",
      "(15, 7) 0.0593292147633\n",
      "(15, 8) 0.0675705036368\n",
      "(15, 9) 0.0532389047736\n",
      "(16, 0) 0.0383065224874\n",
      "(16, 1) 0.0447193933439\n",
      "(16, 2) 0.0517930485611\n",
      "(16, 3) 0.0709617545613\n",
      "(16, 4) 0.0539246929776\n",
      "(16, 5) -0.455575867986\n",
      "(16, 6) 0.0592012489697\n",
      "(16, 7) 0.0606784608337\n",
      "(16, 8) 0.0389547477164\n",
      "(16, 9) 0.0370359985569\n",
      "(17, 0) -0.456984372188\n",
      "(17, 1) 0.0521591528413\n",
      "(17, 2) 0.0381703908037\n",
      "(17, 3) 0.0435148225231\n",
      "(17, 4) 0.0470272903508\n",
      "(17, 5) 0.0531966916073\n",
      "(17, 6) 0.0427774009104\n",
      "(17, 7) 0.0593292147633\n",
      "(17, 8) 0.0675705036368\n",
      "(17, 9) 0.0532389047736\n",
      "(18, 0) -0.456984372166\n",
      "(18, 1) 0.0521591528413\n",
      "(18, 2) 0.0381703908037\n",
      "(18, 3) 0.0435148225231\n",
      "(18, 4) 0.0470272903508\n",
      "(18, 5) 0.0531966916073\n",
      "(18, 6) 0.0427774009104\n",
      "(18, 7) 0.0593292147633\n",
      "(18, 8) 0.0675705036368\n",
      "(18, 9) 0.0532389047736\n",
      "(19, 0) -0.456984372166\n",
      "(19, 1) 0.0521591528413\n",
      "(19, 2) 0.0381703908037\n",
      "(19, 3) 0.0435148225231\n",
      "(19, 4) 0.0470272903508\n",
      "(19, 5) 0.0531966916073\n",
      "(19, 6) 0.0427774009104\n",
      "(19, 7) 0.0593292147633\n",
      "(19, 8) 0.0675705036368\n",
      "(19, 9) 0.0532389047736\n",
      "(20, 0) -0.456984372166\n",
      "(20, 1) 0.0521591528413\n",
      "(20, 2) 0.0381703908037\n",
      "(20, 3) 0.0435148225231\n",
      "(20, 4) 0.0470272903508\n",
      "(20, 5) 0.0531966916073\n",
      "(20, 6) 0.0427774009104\n",
      "(20, 7) 0.0593292147633\n",
      "(20, 8) 0.0675705036368\n",
      "(20, 9) 0.0532389047736\n",
      "(21, 0) 0.0383065224874\n",
      "(21, 1) 0.0447193933439\n",
      "(21, 2) 0.0517930485611\n",
      "(21, 3) 0.0709617545613\n",
      "(21, 4) 0.0539246929776\n",
      "(21, 5) -0.455575867986\n",
      "(21, 6) 0.0592012489697\n",
      "(21, 7) 0.0606784608337\n",
      "(21, 8) 0.0389547477164\n",
      "(21, 9) 0.0370359985569\n",
      "(22, 0) -0.456984372166\n",
      "(22, 1) 0.0521591528413\n",
      "(22, 2) 0.0381703908037\n",
      "(22, 3) 0.0435148225231\n",
      "(22, 4) 0.0470272903508\n",
      "(22, 5) 0.0531966916073\n",
      "(22, 6) 0.0427774009104\n",
      "(22, 7) 0.0593292147633\n",
      "(22, 8) 0.0675705036368\n",
      "(22, 9) 0.0532389047736\n",
      "(23, 0) -0.456984372166\n",
      "(23, 1) 0.0521591528413\n",
      "(23, 2) 0.0381703908037\n",
      "(23, 3) 0.0435148225231\n",
      "(23, 4) 0.0470272903508\n",
      "(23, 5) 0.0531966916073\n",
      "(23, 6) 0.0427774009104\n",
      "(23, 7) 0.0593292147633\n",
      "(23, 8) 0.0675705036368\n",
      "(23, 9) 0.0532389047736\n",
      "(24, 0) 0.0383065224874\n",
      "(24, 1) 0.0447193933439\n",
      "(24, 2) 0.0517930485611\n",
      "(24, 3) 0.0709617545613\n",
      "(24, 4) 0.0539246929776\n",
      "(24, 5) -0.455575867986\n",
      "(24, 6) 0.0592012489697\n",
      "(24, 7) 0.0606784608337\n",
      "(24, 8) 0.0389547477164\n",
      "(24, 9) 0.0370359985569\n",
      "(25, 0) -0.456984372166\n",
      "(25, 1) 0.0521591528413\n",
      "(25, 2) 0.0381703908037\n",
      "(25, 3) 0.0435148225231\n",
      "(25, 4) 0.0470272903508\n",
      "(25, 5) 0.0531966916073\n",
      "(25, 6) 0.0427774009104\n",
      "(25, 7) 0.0593292147633\n",
      "(25, 8) 0.0675705036368\n",
      "(25, 9) 0.0532389047736\n",
      "(26, 0) 0.0383065224874\n",
      "(26, 1) 0.0447193933439\n",
      "(26, 2) 0.0517930485611\n",
      "(26, 3) 0.0709617545613\n",
      "(26, 4) 0.0539246929776\n",
      "(26, 5) -0.455575867986\n",
      "(26, 6) 0.0592012489697\n",
      "(26, 7) 0.0606784608337\n",
      "(26, 8) 0.0389547477164\n",
      "(26, 9) 0.0370359985569\n",
      "(27, 0) -0.456984372166\n",
      "(27, 1) 0.0521591528413\n",
      "(27, 2) 0.0381703908037\n",
      "(27, 3) 0.0435148225231\n",
      "(27, 4) 0.0470272903508\n",
      "(27, 5) 0.0531966916073\n",
      "(27, 6) 0.0427774009104\n",
      "(27, 7) 0.0593292147633\n",
      "(27, 8) 0.0675705036368\n",
      "(27, 9) 0.0532389047736\n",
      "(28, 0) -0.456984372166\n",
      "(28, 1) 0.0521591528413\n",
      "(28, 2) 0.0381703908037\n",
      "(28, 3) 0.0435148225231\n",
      "(28, 4) 0.0470272903508\n",
      "(28, 5) 0.0531966916073\n",
      "(28, 6) 0.0427774009104\n",
      "(28, 7) 0.0593292147633\n",
      "(28, 8) 0.0675705036368\n",
      "(28, 9) 0.0532389047736\n",
      "(29, 0) -0.456984372166\n",
      "(29, 1) 0.0521591528413\n",
      "(29, 2) 0.0381703908037\n",
      "(29, 3) 0.0435148225231\n",
      "(29, 4) 0.0470272903508\n",
      "(29, 5) 0.0531966916073\n",
      "(29, 6) 0.0427774009104\n",
      "(29, 7) 0.0593292147633\n",
      "(29, 8) 0.0675705036368\n",
      "(29, 9) 0.0532389047736\n",
      "W3 relative error: 3.81e-10\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 2.22044604925e-11\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) -2.22044604925e-11\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "b1 relative error: 2.22e-03\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 2.22044604925e-11\n",
      "(6,) 0.0\n",
      "(7,) -2.22044604925e-11\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 2.22044604925e-11\n",
      "(16,) 0.0\n",
      "(17,) 2.22044604925e-11\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "(20,) 0.0\n",
      "(21,) 0.0\n",
      "(22,) 0.0\n",
      "(23,) 0.0\n",
      "(24,) 0.0\n",
      "(25,) 0.0\n",
      "(26,) 0.0\n",
      "(27,) 0.0\n",
      "(28,) 0.0\n",
      "(29,) 0.0\n",
      "b2 relative error: 2.22e-03\n",
      "(0,) -0.418677849678\n",
      "(1,) 0.096878546163\n",
      "(2,) 0.0899634393425\n",
      "(3,) 0.114476577107\n",
      "(4,) 0.100951983351\n",
      "(5,) -0.402379176356\n",
      "(6,) 0.10197864988\n",
      "(7,) 0.120007675597\n",
      "(8,) 0.106525251353\n",
      "(9,) 0.0902749033305\n",
      "b3 relative error: 1.64e-10\n",
      "\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  6.8422824047\n",
      "(0, 0) -0.101612616987\n",
      "(0, 1) 0.105691850516\n",
      "(0, 2) 0.0760441306813\n",
      "(0, 3) 0.0883480457681\n",
      "(0, 4) 0.0119182448799\n",
      "(0, 5) -0.136087052383\n",
      "(0, 6) -0.0998010712294\n",
      "(0, 7) 0.135188332528\n",
      "(0, 8) 0.0819734789381\n",
      "(0, 9) 0.00753956355126\n",
      "(0, 10) -0.325484097807\n",
      "(0, 11) 0.393682546029\n",
      "(0, 12) 0.210955781377\n",
      "(0, 13) 0.0938563136987\n",
      "(0, 14) 0.184100475842\n",
      "(0, 15) 0.00614890787176\n",
      "(0, 16) 0.0757839168308\n",
      "(0, 17) -0.0157569805204\n",
      "(0, 18) 0.209926234618\n",
      "(0, 19) -0.0439581359313\n",
      "(1, 0) -0.0893910717892\n",
      "(1, 1) 0.103647835203\n",
      "(1, 2) 0.240197956103\n",
      "(1, 3) -0.0494498727299\n",
      "(1, 4) -0.120088022149\n",
      "(1, 5) -0.141672413356\n",
      "(1, 6) 0.22743229513\n",
      "(1, 7) 0.0573063874576\n",
      "(1, 8) -0.145503525317\n",
      "(1, 9) -0.0739676552008\n",
      "(1, 10) -0.0696929807198\n",
      "(1, 11) 0.185745531578\n",
      "(1, 12) 0.09434843804\n",
      "(1, 13) 0.000111771392142\n",
      "(1, 14) 0.188890276087\n",
      "(1, 15) -0.0219422517489\n",
      "(1, 16) -0.112527268348\n",
      "(1, 17) -0.01047956526\n",
      "(1, 18) 0.2888949997\n",
      "(1, 19) 0.0359469071398\n",
      "(2, 0) -0.141825342581\n",
      "(2, 1) 0.0654993302263\n",
      "(2, 2) -0.0966824766024\n",
      "(2, 3) -0.0685565050951\n",
      "(2, 4) 0.0921800853426\n",
      "(2, 5) 0.213876745381\n",
      "(2, 6) 0.0610282743452\n",
      "(2, 7) -0.299734866838\n",
      "(2, 8) -0.133031986671\n",
      "(2, 9) 0.105304380327\n",
      "(2, 10) 0.224892870637\n",
      "(2, 11) 0.192377070629\n",
      "(2, 12) -0.0089797712377\n",
      "(2, 13) 0.093399284129\n",
      "(2, 14) 0.0572900571871\n",
      "(2, 15) 0.186469483321\n",
      "(2, 16) 0.333970732447\n",
      "(2, 17) -0.0843050433019\n",
      "(2, 18) 0.0102828499937\n",
      "(2, 19) -0.0202568319452\n",
      "(3, 0) -0.202656821191\n",
      "(3, 1) -0.0552053034841\n",
      "(3, 2) 0.166535111434\n",
      "(3, 3) 0.0256700026569\n",
      "(3, 4) -0.256690604683\n",
      "(3, 5) -0.386932373964\n",
      "(3, 6) -0.223853348391\n",
      "(3, 7) -0.175511311262\n",
      "(3, 8) 0.0573317341601\n",
      "(3, 9) 0.0145209860136\n",
      "(3, 10) -0.132080911808\n",
      "(3, 11) -0.251926042871\n",
      "(3, 12) -0.1867357589\n",
      "(3, 13) -0.0334625067211\n",
      "(3, 14) -0.390106843051\n",
      "(3, 15) 0.130838672474\n",
      "(3, 16) 0.105764030423\n",
      "(3, 17) -0.185001997099\n",
      "(3, 18) 0.0935220877629\n",
      "(3, 19) 0.108074752259\n",
      "(4, 0) -0.0388821038921\n",
      "(4, 1) -0.183678191545\n",
      "(4, 2) -0.0978971699261\n",
      "(4, 3) -0.0339221621459\n",
      "(4, 4) -0.143758442306\n",
      "(4, 5) -0.27975459993\n",
      "(4, 6) 0.0720055115089\n",
      "(4, 7) -0.155065653207\n",
      "(4, 8) 0.291915142636\n",
      "(4, 9) 0.219284218117\n",
      "(4, 10) 0.130122518804\n",
      "(4, 11) 0.00252928185063\n",
      "(4, 12) 0.252223584685\n",
      "(4, 13) 0.0449731071939\n",
      "(4, 14) -0.023491858725\n",
      "(4, 15) -0.0415405254195\n",
      "(4, 16) 0.0353683067278\n",
      "(4, 17) -0.0145081132885\n",
      "(4, 18) 0.120314824503\n",
      "(4, 19) -0.0262740617707\n",
      "(5, 0) 0.138075912925\n",
      "(5, 1) -0.105783822502\n",
      "(5, 2) -0.177786818911\n",
      "(5, 3) -0.0588558939363\n",
      "(5, 4) -0.0128339523009\n",
      "(5, 5) -0.0612331114258\n",
      "(5, 6) 0.217711913786\n",
      "(5, 7) 0.162744303944\n",
      "(5, 8) -0.0181245813913\n",
      "(5, 9) 0.219487488984\n",
      "(5, 10) -0.428772976502\n",
      "(5, 11) -0.090429936872\n",
      "(5, 12) -0.0334974322058\n",
      "(5, 13) 0.00444260317423\n",
      "(5, 14) -0.170805482114\n",
      "(5, 15) -0.117124205401\n",
      "(5, 16) -0.0634881614392\n",
      "(5, 17) 0.101683437492\n",
      "(5, 18) -0.162894706612\n",
      "(5, 19) 0.0802310397674\n",
      "(6, 0) -0.0364309829415\n",
      "(6, 1) 0.286534688199\n",
      "(6, 2) 0.170030203073\n",
      "(6, 3) 0.303357930109\n",
      "(6, 4) 0.113259729506\n",
      "(6, 5) 0.0677854843367\n",
      "(6, 6) -0.0385671296232\n",
      "(6, 7) 0.11388527188\n",
      "(6, 8) 0.148219974072\n",
      "(6, 9) 0.0729790386789\n",
      "(6, 10) -0.181689551537\n",
      "(6, 11) -0.147406857209\n",
      "(6, 12) -0.129887337463\n",
      "(6, 13) 0.0858019361782\n",
      "(6, 14) 0.0820695449377\n",
      "(6, 15) -0.0470887468573\n",
      "(6, 16) -0.159932401855\n",
      "(6, 17) -0.0217677373904\n",
      "(6, 18) 0.240238449223\n",
      "(6, 19) -0.0716044804783\n",
      "(7, 0) 0.283542680268\n",
      "(7, 1) -0.0590390083488\n",
      "(7, 2) -0.161053302072\n",
      "(7, 3) 0.0524590771267\n",
      "(7, 4) 0.0409670927848\n",
      "(7, 5) 0.0109593107922\n",
      "(7, 6) -0.0426926407116\n",
      "(7, 7) 0.0557033291493\n",
      "(7, 8) 0.118992120024\n",
      "(7, 9) 0.248922760004\n",
      "(7, 10) -0.0967269805585\n",
      "(7, 11) 0.00853265222922\n",
      "(7, 12) 0.0749290484769\n",
      "(7, 13) 0.0115773605369\n",
      "(7, 14) -0.100642769763\n",
      "(7, 15) 0.146492539077\n",
      "(7, 16) -0.256604309445\n",
      "(7, 17) 0.119927959874\n",
      "(7, 18) 0.0166759581255\n",
      "(7, 19) 0.0558037484666\n",
      "(8, 0) 0.156299357457\n",
      "(8, 1) -0.00378903290965\n",
      "(8, 2) 0.28188116783\n",
      "(8, 3) 0.22851586845\n",
      "(8, 4) 0.0559383595888\n",
      "(8, 5) 0.214411367327\n",
      "(8, 6) -0.0184884287435\n",
      "(8, 7) 0.180633635782\n",
      "(8, 8) -0.138321865339\n",
      "(8, 9) 0.198985230027\n",
      "(8, 10) 0.111275117831\n",
      "(8, 11) 0.0015998767644\n",
      "(8, 12) 0.144889912379\n",
      "(8, 13) 0.155547342917\n",
      "(8, 14) -0.17638894616\n",
      "(8, 15) -0.041448727961\n",
      "(8, 16) -0.0703464389851\n",
      "(8, 17) -0.0121888808824\n",
      "(8, 18) -0.158840124875\n",
      "(8, 19) 0.0374473225762\n",
      "(9, 0) 0.219301400106\n",
      "(9, 1) -0.0982725530285\n",
      "(9, 2) 0.0460045489703\n",
      "(9, 3) 0.0182727107223\n",
      "(9, 4) 0.1598644082\n",
      "(9, 5) -0.142789624213\n",
      "(9, 6) 0.164534766078\n",
      "(9, 7) -0.0875208780116\n",
      "(9, 8) 0.190105781206\n",
      "(9, 9) -0.239359257748\n",
      "(9, 10) -0.183056705749\n",
      "(9, 11) 0.000986990578156\n",
      "(9, 12) -0.105939164108\n",
      "(9, 13) 0.213620541878\n",
      "(9, 14) -0.0590100581732\n",
      "(9, 15) -0.0310558927019\n",
      "(9, 16) 0.240872219637\n",
      "(9, 17) -0.131549909543\n",
      "(9, 18) -0.185120462959\n",
      "(9, 19) -0.0843605624024\n",
      "(10, 0) 0.229992604961\n",
      "(10, 1) 0.0979599741324\n",
      "(10, 2) 0.19565292555\n",
      "(10, 3) 0.1831827662\n",
      "(10, 4) 0.00291315931378\n",
      "(10, 5) -0.0604670535864\n",
      "(10, 6) -0.00899058365533\n",
      "(10, 7) -0.0984989194208\n",
      "(10, 8) 0.0869622143185\n",
      "(10, 9) -0.0715100412219\n",
      "(10, 10) 0.0374639145484\n",
      "(10, 11) -0.163966207278\n",
      "(10, 12) 0.113984034877\n",
      "(10, 13) -0.178133072959\n",
      "(10, 14) -0.2326790006\n",
      "(10, 15) 0.1862103713\n",
      "(10, 16) 0.0498766587587\n",
      "(10, 17) -0.103009765207\n",
      "(10, 18) 0.137942873391\n",
      "(10, 19) -0.112867660906\n",
      "(11, 0) 0.115530200917\n",
      "(11, 1) 0.0774139574222\n",
      "(11, 2) -0.0201042999137\n",
      "(11, 3) 0.073963420899\n",
      "(11, 4) 0.183763287787\n",
      "(11, 5) 0.130360701966\n",
      "(11, 6) -0.139625018525\n",
      "(11, 7) 0.0826306216339\n",
      "(11, 8) 0.279862404318\n",
      "(11, 9) -0.176741803104\n",
      "(11, 10) 0.086766078855\n",
      "(11, 11) -0.0302258153617\n",
      "(11, 12) -0.0459531571018\n",
      "(11, 13) 0.145940784613\n",
      "(11, 14) 0.0804132863408\n",
      "(11, 15) -0.0294935530665\n",
      "(11, 16) -0.241140013157\n",
      "(11, 17) 0.276355990048\n",
      "(11, 18) -0.203855897229\n",
      "(11, 19) 0.131051231955\n",
      "(12, 0) 0.139109676844\n",
      "(12, 1) -0.205254102337\n",
      "(12, 2) -0.12729917227\n",
      "(12, 3) -0.0931167627449\n",
      "(12, 4) -0.0667271722321\n",
      "(12, 5) -0.0667620700057\n",
      "(12, 6) 0.104290355596\n",
      "(12, 7) 0.0794096184364\n",
      "(12, 8) 0.168097127151\n",
      "(12, 9) 0.0538501510494\n",
      "(12, 10) 0.196516960571\n",
      "(12, 11) 0.0567912982419\n",
      "(12, 12) 0.168373653242\n",
      "(12, 13) 0.139088057516\n",
      "(12, 14) 0.120329644027\n",
      "(12, 15) -0.0492446524891\n",
      "(12, 16) 0.0325270098411\n",
      "(12, 17) 0.0166646621835\n",
      "(12, 18) 0.0149161166973\n",
      "(12, 19) -0.0856000414107\n",
      "(13, 0) -0.0749340444806\n",
      "(13, 1) 0.332552986526\n",
      "(13, 2) 0.125845555132\n",
      "(13, 3) -0.0380364642005\n",
      "(13, 4) -0.0238262416907\n",
      "(13, 5) 0.0259954929138\n",
      "(13, 6) -0.0312889712362\n",
      "(13, 7) 0.180164261732\n",
      "(13, 8) -0.157833961811\n",
      "(13, 9) 0.16049376903\n",
      "(13, 10) 0.229366302618\n",
      "(13, 11) -0.0262800631479\n",
      "(13, 12) -0.113223737896\n",
      "(13, 13) 0.0824532705224\n",
      "(13, 14) -0.0889391795766\n",
      "(13, 15) 0.0992147728418\n",
      "(13, 16) -0.0715775954063\n",
      "(13, 17) -0.29684123799\n",
      "(13, 18) -0.159465618665\n",
      "(13, 19) 0.0517611545625\n",
      "(14, 0) -0.0808280771203\n",
      "(14, 1) -0.0872122329021\n",
      "(14, 2) -0.168869575212\n",
      "(14, 3) 0.199770275078\n",
      "(14, 4) 0.0204751820387\n",
      "(14, 5) -0.105246528381\n",
      "(14, 6) 0.107026300178\n",
      "(14, 7) 0.0725399782908\n",
      "(14, 8) -0.113870276941\n",
      "(14, 9) -0.147250657179\n",
      "(14, 10) -0.297045362663\n",
      "(14, 11) 0.087745704791\n",
      "(14, 12) 0.116380659332\n",
      "(14, 13) -0.0627493602856\n",
      "(14, 14) 0.0807729855445\n",
      "(14, 15) -0.317260730665\n",
      "(14, 16) -0.129965514173\n",
      "(14, 17) -0.18332955749\n",
      "(14, 18) 0.0232472866291\n",
      "(14, 19) 0.211549282358\n",
      "W1 relative error: 2.66e-02\n",
      "(0, 0) 0.0369098849262\n",
      "(0, 1) 0.00805809201587\n",
      "(0, 2) 0.0890608856885\n",
      "(0, 3) 0.0785585737351\n",
      "(0, 4) -0.0136304475262\n",
      "(0, 5) -0.0669582305601\n",
      "(0, 6) 0.0788207433544\n",
      "(0, 7) -0.209277235408\n",
      "(0, 8) -0.132456174962\n",
      "(0, 9) 0.0942650026037\n",
      "(0, 10) 0.123118396367\n",
      "(0, 11) 0.0960467080091\n",
      "(0, 12) -0.111583159956\n",
      "(0, 13) 0.137723571969\n",
      "(0, 14) 0.0503998429213\n",
      "(0, 15) 0.0779274526685\n",
      "(0, 16) -0.03302069711\n",
      "(0, 17) -0.0594682495247\n",
      "(0, 18) -0.00733394056596\n",
      "(0, 19) 0.107290595697\n",
      "(0, 20) 0.151164258311\n",
      "(0, 21) 0.0868198417159\n",
      "(0, 22) -0.147228324243\n",
      "(0, 23) -0.0066523610176\n",
      "(0, 24) 0.00893188603079\n",
      "(0, 25) 0.151768190237\n",
      "(0, 26) -0.511616978294\n",
      "(0, 27) -0.194871859183\n",
      "(0, 28) 0.00890439246781\n",
      "(0, 29) -0.00495357808106\n",
      "(1, 0) -0.0580752026469\n",
      "(1, 1) 0.0613857755738\n",
      "(1, 2) 0.210259586808\n",
      "(1, 3) 0.123809711861\n",
      "(1, 4) 0.0147633180347\n",
      "(1, 5) -0.00643669024747\n",
      "(1, 6) 0.163452330648\n",
      "(1, 7) -0.329232913199\n",
      "(1, 8) 0.079367738115\n",
      "(1, 9) -0.152188654745\n",
      "(1, 10) 0.0137855074023\n",
      "(1, 11) -0.107794911841\n",
      "(1, 12) 0.0514059369738\n",
      "(1, 13) 0.0326350244162\n",
      "(1, 14) 0.29317849366\n",
      "(1, 15) -0.0833966793401\n",
      "(1, 16) 0.0583772716389\n",
      "(1, 17) 0.100849116436\n",
      "(1, 18) 0.296124594179\n",
      "(1, 19) -0.115412643309\n",
      "(1, 20) 0.0373832976575\n",
      "(1, 21) -0.0190840312442\n",
      "(1, 22) -0.201794168486\n",
      "(1, 23) -0.0557383046385\n",
      "(1, 24) 0.116387096849\n",
      "(1, 25) 0.0992604419103\n",
      "(1, 26) 0.0176341106606\n",
      "(1, 27) 0.130518669117\n",
      "(1, 28) -0.142155239269\n",
      "(1, 29) -0.0316852468707\n",
      "(2, 0) 0.280872781344\n",
      "(2, 1) -0.271150060405\n",
      "(2, 2) -0.0184564535655\n",
      "(2, 3) -0.117620338624\n",
      "(2, 4) -0.213657657788\n",
      "(2, 5) 0.087354723366\n",
      "(2, 6) 0.0924095929555\n",
      "(2, 7) 0.0435977126845\n",
      "(2, 8) -0.345855018002\n",
      "(2, 9) -0.229322249368\n",
      "(2, 10) 0.075135737676\n",
      "(2, 11) 0.0931112414282\n",
      "(2, 12) 0.175287920756\n",
      "(2, 13) -0.2584343751\n",
      "(2, 14) -0.207732731905\n",
      "(2, 15) 0.25421356149\n",
      "(2, 16) 0.00215323270325\n",
      "(2, 17) -0.181728101278\n",
      "(2, 18) -0.101919000572\n",
      "(2, 19) -0.0453136530076\n",
      "(2, 20) 0.285158899027\n",
      "(2, 21) 0.125070943691\n",
      "(2, 22) -0.0311407962084\n",
      "(2, 23) -0.138251211634\n",
      "(2, 24) 0.0628138667746\n",
      "(2, 25) -0.265375053576\n",
      "(2, 26) 0.0666943554606\n",
      "(2, 27) -0.180928081717\n",
      "(2, 28) 0.0533659461066\n",
      "(2, 29) -0.15344230655\n",
      "(3, 0) -0.260597900281\n",
      "(3, 1) 0.124492170261\n",
      "(3, 2) -0.156027560294\n",
      "(3, 3) -0.048627763638\n",
      "(3, 4) 0.118131254689\n",
      "(3, 5) -0.00583782511221\n",
      "(3, 6) -0.00522288550187\n",
      "(3, 7) -0.094336076506\n",
      "(3, 8) 0.00672320559225\n",
      "(3, 9) -0.0874201899315\n",
      "(3, 10) -0.15333176866\n",
      "(3, 11) 0.168962723501\n",
      "(3, 12) 0.217516599355\n",
      "(3, 13) 0.269379368101\n",
      "(3, 14) -0.188145415825\n",
      "(3, 15) 0.058904497191\n",
      "(3, 16) 0.0235200701137\n",
      "(3, 17) -0.219757129472\n",
      "(3, 18) 0.0461206895341\n",
      "(3, 19) -0.0243234417052\n",
      "(3, 20) 0.0773355842476\n",
      "(3, 21) 0.080555643267\n",
      "(3, 22) 0.100026817229\n",
      "(3, 23) -0.0162047168573\n",
      "(3, 24) 0.0833641679687\n",
      "(3, 25) -0.183836543322\n",
      "(3, 26) 0.080077420872\n",
      "(3, 27) 0.164594104746\n",
      "(3, 28) 0.133586114082\n",
      "(3, 29) 0.0551781053293\n",
      "(4, 0) -0.255037412078\n",
      "(4, 1) -0.0551226489787\n",
      "(4, 2) 0.00874752066338\n",
      "(4, 3) 0.0133973618865\n",
      "(4, 4) -0.119605897408\n",
      "(4, 5) -0.0581708227365\n",
      "(4, 6) 0.0238815260456\n",
      "(4, 7) 0.102131066271\n",
      "(4, 8) -0.16776862668\n",
      "(4, 9) -0.167560511155\n",
      "(4, 10) 0.0227146084608\n",
      "(4, 11) -0.0899589789327\n",
      "(4, 12) 0.241078357943\n",
      "(4, 13) -0.11875739645\n",
      "(4, 14) 0.0299507156853\n",
      "(4, 15) 0.00568146143465\n",
      "(4, 16) -0.0292097606991\n",
      "(4, 17) -0.0168376027787\n",
      "(4, 18) 0.0765736057229\n",
      "(4, 19) -0.137345173234\n",
      "(4, 20) 0.0612015947699\n",
      "(4, 21) 0.0975209262677\n",
      "(4, 22) 0.103852080446\n",
      "(4, 23) 0.156919778016\n",
      "(4, 24) -0.0302951331133\n",
      "(4, 25) -0.340937157572\n",
      "(4, 26) 0.190753588036\n",
      "(4, 27) -0.0125088661207\n",
      "(4, 28) 0.0554932610086\n",
      "(4, 29) -0.173006246973\n",
      "(5, 0) -0.0408993228174\n",
      "(5, 1) -0.198764571291\n",
      "(5, 2) 0.219057475892\n",
      "(5, 3) -0.190578791104\n",
      "(5, 4) 0.0935482594944\n",
      "(5, 5) -0.0953101561674\n",
      "(5, 6) 0.0469506447942\n",
      "(5, 7) 0.249419568954\n",
      "(5, 8) 0.115166983994\n",
      "(5, 9) -0.299011409055\n",
      "(5, 10) 0.024698320189\n",
      "(5, 11) -0.10438831497\n",
      "(5, 12) 0.109516128211\n",
      "(5, 13) 0.0102669762025\n",
      "(5, 14) 0.200388295291\n",
      "(5, 15) -0.265577733494\n",
      "(5, 16) 0.101971374722\n",
      "(5, 17) -0.0424277169397\n",
      "(5, 18) -0.250725277562\n",
      "(5, 19) 0.106284583179\n",
      "(5, 20) -0.0233716586528\n",
      "(5, 21) -0.115447449645\n",
      "(5, 22) -0.251057064515\n",
      "(5, 23) 0.147843890463\n",
      "(5, 24) 0.128653419695\n",
      "(5, 25) -0.0500644517398\n",
      "(5, 26) 0.0992528310206\n",
      "(5, 27) 0.204407613724\n",
      "(5, 28) -0.235200564491\n",
      "(5, 29) 0.161756283568\n",
      "(6, 0) 0.0559214136331\n",
      "(6, 1) -0.0481556535092\n",
      "(6, 2) -0.375676628694\n",
      "(6, 3) -0.0305281761204\n",
      "(6, 4) 0.016350593679\n",
      "(6, 5) -0.060271282365\n",
      "(6, 6) -0.0504178089944\n",
      "(6, 7) 0.151262467929\n",
      "(6, 8) -0.226952645166\n",
      "(6, 9) -0.110427387767\n",
      "(6, 10) 0.158756593827\n",
      "(6, 11) -0.0900075499022\n",
      "(6, 12) 0.00596096949579\n",
      "(6, 13) 0.411062594274\n",
      "(6, 14) 0.247760176064\n",
      "(6, 15) 0.0520709643403\n",
      "(6, 16) 0.0792325493215\n",
      "(6, 17) -0.00157704929116\n",
      "(6, 18) -0.0478370088874\n",
      "(6, 19) -0.111726308383\n",
      "(6, 20) -0.0756849110495\n",
      "(6, 21) 0.0847236571566\n",
      "(6, 22) 0.00696347761675\n",
      "(6, 23) -0.298755481465\n",
      "(6, 24) 0.0525970532461\n",
      "(6, 25) 0.0393330590764\n",
      "(6, 26) 0.147302231568\n",
      "(6, 27) 0.243138569189\n",
      "(6, 28) 0.0127780224624\n",
      "(6, 29) 0.46130078819\n",
      "(7, 0) -0.0910473183069\n",
      "(7, 1) 0.109866163855\n",
      "(7, 2) -0.129942226357\n",
      "(7, 3) 0.138381920767\n",
      "(7, 4) 0.128480916173\n",
      "(7, 5) 0.107131150751\n",
      "(7, 6) -0.112126498486\n",
      "(7, 7) -0.38490386447\n",
      "(7, 8) -0.123100055749\n",
      "(7, 9) 0.174287897003\n",
      "(7, 10) -0.143784238604\n",
      "(7, 11) 0.226355562249\n",
      "(7, 12) 0.398778086241\n",
      "(7, 13) 0.0950951796419\n",
      "(7, 14) -0.0244855836939\n",
      "(7, 15) -0.129237979696\n",
      "(7, 16) 0.134232508664\n",
      "(7, 17) -0.00804866342463\n",
      "(7, 18) -0.0622572256415\n",
      "(7, 19) -0.142726156893\n",
      "(7, 20) 0.178793195182\n",
      "(7, 21) -0.207299720323\n",
      "(7, 22) -0.226431811079\n",
      "(7, 23) -0.10693956316\n",
      "(7, 24) -0.00129436981133\n",
      "(7, 25) 0.080544253267\n",
      "(7, 26) -0.0600842567255\n",
      "(7, 27) 0.0791632004837\n",
      "(7, 28) -0.0621791879762\n",
      "(7, 29) 0.0141639119988\n",
      "(8, 0) -0.034782701519\n",
      "(8, 1) 0.348612751688\n",
      "(8, 2) 0.0473634992115\n",
      "(8, 3) 0.0316613952833\n",
      "(8, 4) 0.0847160384954\n",
      "(8, 5) 0.285737391303\n",
      "(8, 6) 0.00734906269173\n",
      "(8, 7) 0.129297559992\n",
      "(8, 8) -0.00155302379845\n",
      "(8, 9) -0.0446978111857\n",
      "(8, 10) 0.132244216156\n",
      "(8, 11) -0.301112918422\n",
      "(8, 12) 0.0999316800421\n",
      "(8, 13) -0.0678528303766\n",
      "(8, 14) -0.182915052882\n",
      "(8, 15) 0.0524734156571\n",
      "(8, 16) 0.181223301965\n",
      "(8, 17) -0.00655251390924\n",
      "(8, 18) 0.0992657961163\n",
      "(8, 19) -0.0427753543697\n",
      "(8, 20) 0.345477654706\n",
      "(8, 21) -0.151541143678\n",
      "(8, 22) 0.312998620977\n",
      "(8, 23) 0.282345721159\n",
      "(8, 24) 0.00841080121106\n",
      "(8, 25) 0.127586918142\n",
      "(8, 26) -0.0140487430134\n",
      "(8, 27) -0.0460201287744\n",
      "(8, 28) -0.0808600258306\n",
      "(8, 29) -0.0682154594145\n",
      "(9, 0) 0.0997593762264\n",
      "(9, 1) 0.0683833643933\n",
      "(9, 2) -0.0504876743523\n",
      "(9, 3) 0.148203731376\n",
      "(9, 4) 0.0790137660189\n",
      "(9, 5) 0.159977556047\n",
      "(9, 6) -0.0249908003624\n",
      "(9, 7) -0.0698294867707\n",
      "(9, 8) -0.00224747611632\n",
      "(9, 9) -0.125159273967\n",
      "(9, 10) 0.0759908278081\n",
      "(9, 11) 0.0356454785244\n",
      "(9, 12) 0.128342657524\n",
      "(9, 13) -0.0342169665934\n",
      "(9, 14) -0.0978366755611\n",
      "(9, 15) 0.246897643796\n",
      "(9, 16) -0.0702558476284\n",
      "(9, 17) -0.41290829369\n",
      "(9, 18) 0.323227330501\n",
      "(9, 19) -0.077929958664\n",
      "(9, 20) 0.135628114295\n",
      "(9, 21) -0.218054150913\n",
      "(9, 22) 0.109397105374\n",
      "(9, 23) -0.172052921021\n",
      "(9, 24) 0.342472239723\n",
      "(9, 25) -0.464121460508\n",
      "(9, 26) -0.105756444224\n",
      "(9, 27) -0.128900905016\n",
      "(9, 28) -0.0292053143447\n",
      "(9, 29) 0.0957440520644\n",
      "(10, 0) -0.0806888100335\n",
      "(10, 1) 0.276974727287\n",
      "(10, 2) 0.101257902063\n",
      "(10, 3) -0.130659481679\n",
      "(10, 4) -0.1115895782\n",
      "(10, 5) 0.110165649669\n",
      "(10, 6) -0.0948991786931\n",
      "(10, 7) 0.114597555712\n",
      "(10, 8) 0.0530645848151\n",
      "(10, 9) -0.278052779956\n",
      "(10, 10) -0.204312196406\n",
      "(10, 11) 0.0590830455671\n",
      "(10, 12) -0.0249162803723\n",
      "(10, 13) -0.00622814586571\n",
      "(10, 14) 0.168206626538\n",
      "(10, 15) 0.0402241711051\n",
      "(10, 16) 0.208362953558\n",
      "(10, 17) -0.0378639393173\n",
      "(10, 18) 0.0612729680771\n",
      "(10, 19) -0.0386253874218\n",
      "(10, 20) -0.0526979023086\n",
      "(10, 21) 0.114616122904\n",
      "(10, 22) -0.0329954608969\n",
      "(10, 23) -0.0467124303238\n",
      "(10, 24) 0.0686562171115\n",
      "(10, 25) -0.12963369711\n",
      "(10, 26) -0.156028401488\n",
      "(10, 27) -0.145157365417\n",
      "(10, 28) 0.0469338155007\n",
      "(10, 29) 0.0635463607068\n",
      "(11, 0) 0.127751275247\n",
      "(11, 1) 0.148111950482\n",
      "(11, 2) -0.141716253088\n",
      "(11, 3) 0.0992612874562\n",
      "(11, 4) 0.0983467130844\n",
      "(11, 5) -0.0415912019047\n",
      "(11, 6) 0.131836221895\n",
      "(11, 7) 0.209428443343\n",
      "(11, 8) 0.111246456047\n",
      "(11, 9) 0.170679764988\n",
      "(11, 10) -0.0337398962547\n",
      "(11, 11) 0.0421992062183\n",
      "(11, 12) -0.100180094265\n",
      "(11, 13) -0.0170544595335\n",
      "(11, 14) -0.142364414524\n",
      "(11, 15) 0.0256873171178\n",
      "(11, 16) 0.0985062145631\n",
      "(11, 17) -0.24385923556\n",
      "(11, 18) 0.018507622368\n",
      "(11, 19) 0.198325074674\n",
      "(11, 20) -0.0346549374086\n",
      "(11, 21) -0.00258304062584\n",
      "(11, 22) 0.247034276901\n",
      "(11, 23) -0.121639775275\n",
      "(11, 24) 0.00448047861035\n",
      "(11, 25) 0.0714267408775\n",
      "(11, 26) 0.295936778949\n",
      "(11, 27) -0.0869764846811\n",
      "(11, 28) 0.0232740565487\n",
      "(11, 29) -0.0363355817434\n",
      "(12, 0) 0.138774743608\n",
      "(12, 1) -0.16201635451\n",
      "(12, 2) -0.107564226104\n",
      "(12, 3) -0.113980025862\n",
      "(12, 4) 0.168393044842\n",
      "(12, 5) 0.210874881246\n",
      "(12, 6) -0.0203949468869\n",
      "(12, 7) -0.0889433684925\n",
      "(12, 8) -0.239087711096\n",
      "(12, 9) -0.199899908093\n",
      "(12, 10) 0.358861464544\n",
      "(12, 11) 0.0436342005194\n",
      "(12, 12) 0.124229520493\n",
      "(12, 13) -0.270271048119\n",
      "(12, 14) 0.0827646585044\n",
      "(12, 15) -0.374390937408\n",
      "(12, 16) 0.132868539549\n",
      "(12, 17) -0.0126367516007\n",
      "(12, 18) 0.0804854825454\n",
      "(12, 19) 0.320104359863\n",
      "(12, 20) 0.178943216778\n",
      "(12, 21) 0.0844592338289\n",
      "(12, 22) 0.0583107511165\n",
      "(12, 23) 0.0326770503545\n",
      "(12, 24) 0.00686608201406\n",
      "(12, 25) 0.230296059334\n",
      "(12, 26) 0.0502798695123\n",
      "(12, 27) -0.391775759701\n",
      "(12, 28) 0.147307682052\n",
      "(12, 29) 0.268331437381\n",
      "(13, 0) -0.0748000650308\n",
      "(13, 1) 0.10395231369\n",
      "(13, 2) 0.217650063572\n",
      "(13, 3) -0.152366263739\n",
      "(13, 4) -0.124919109279\n",
      "(13, 5) -0.132533403718\n",
      "(13, 6) -0.175597306207\n",
      "(13, 7) -0.00205734305148\n",
      "(13, 8) -0.243253674936\n",
      "(13, 9) 0.301241565515\n",
      "(13, 10) -0.034591914666\n",
      "(13, 11) -0.0889452993924\n",
      "(13, 12) 0.000361581653507\n",
      "(13, 13) 0.0759779919868\n",
      "(13, 14) -0.0568435129633\n",
      "(13, 15) -0.0601211291862\n",
      "(13, 16) -0.197185131601\n",
      "(13, 17) -0.0395490682426\n",
      "(13, 18) -0.220634710368\n",
      "(13, 19) -0.012978126529\n",
      "(13, 20) -0.0291728007973\n",
      "(13, 21) -0.00700399991338\n",
      "(13, 22) 0.105034540843\n",
      "(13, 23) 0.164720807394\n",
      "(13, 24) -0.226746583376\n",
      "(13, 25) 0.131047081009\n",
      "(13, 26) -0.0624000994431\n",
      "(13, 27) 0.101816216613\n",
      "(13, 28) 0.0397612629932\n",
      "(13, 29) -0.284002086604\n",
      "(14, 0) 0.0155682756908\n",
      "(14, 1) -0.0828151111243\n",
      "(14, 2) 0.150138127974\n",
      "(14, 3) -0.106480707407\n",
      "(14, 4) 0.0961037284863\n",
      "(14, 5) 0.0237709556039\n",
      "(14, 6) 0.0249253074625\n",
      "(14, 7) -0.015298484346\n",
      "(14, 8) 0.0355290323828\n",
      "(14, 9) -0.0949115560367\n",
      "(14, 10) 0.158508206605\n",
      "(14, 11) -0.0232116795562\n",
      "(14, 12) 0.0346784850613\n",
      "(14, 13) 0.27909251954\n",
      "(14, 14) 0.229516988259\n",
      "(14, 15) 0.217191372043\n",
      "(14, 16) 0.0326357278979\n",
      "(14, 17) 0.258206311532\n",
      "(14, 18) -0.189117709137\n",
      "(14, 19) -0.102570915583\n",
      "(14, 20) 0.177333783435\n",
      "(14, 21) 0.135472309726\n",
      "(14, 22) -0.0505497299574\n",
      "(14, 23) 0.099685992927\n",
      "(14, 24) 0.0494794634154\n",
      "(14, 25) 0.342663683828\n",
      "(14, 26) -0.0841992489065\n",
      "(14, 27) 0.111185549434\n",
      "(14, 28) -0.0576424540988\n",
      "(14, 29) 0.155159497339\n",
      "(15, 0) 0.11970023821\n",
      "(15, 1) -0.183439344337\n",
      "(15, 2) -0.0697524026982\n",
      "(15, 3) 0.0893100094324\n",
      "(15, 4) -0.0179220998486\n",
      "(15, 5) 0.067761683864\n",
      "(15, 6) 0.221983333848\n",
      "(15, 7) 0.141256921715\n",
      "(15, 8) -0.185414578846\n",
      "(15, 9) -0.0693754663939\n",
      "(15, 10) -0.300550275778\n",
      "(15, 11) 0.118272784411\n",
      "(15, 12) -0.0254738024896\n",
      "(15, 13) -0.209052277089\n",
      "(15, 14) -0.0282268620921\n",
      "(15, 15) 0.0482160719795\n",
      "(15, 16) -0.149923322112\n",
      "(15, 17) -0.0798537193258\n",
      "(15, 18) -0.0200277127327\n",
      "(15, 19) -0.278593897418\n",
      "(15, 20) -0.0288959240091\n",
      "(15, 21) 0.258966249422\n",
      "(15, 22) 0.259091107235\n",
      "(15, 23) -0.0845754497103\n",
      "(15, 24) 0.105381734716\n",
      "(15, 25) -0.064814105416\n",
      "(15, 26) 0.266013667183\n",
      "(15, 27) -0.267483800176\n",
      "(15, 28) 0.190815517565\n",
      "(15, 29) -0.210545706292\n",
      "(16, 0) -0.0480697740279\n",
      "(16, 1) -0.111391564994\n",
      "(16, 2) -0.198222147718\n",
      "(16, 3) -0.0957947670077\n",
      "(16, 4) 0.0334112295164\n",
      "(16, 5) 0.198320238587\n",
      "(16, 6) 0.207487924397\n",
      "(16, 7) -0.226334800146\n",
      "(16, 8) 0.0200371701009\n",
      "(16, 9) 0.277860495768\n",
      "(16, 10) -0.340693141831\n",
      "(16, 11) -0.0993999411669\n",
      "(16, 12) -0.0952451708613\n",
      "(16, 13) 0.0982459609666\n",
      "(16, 14) 0.120192026198\n",
      "(16, 15) 0.103462237222\n",
      "(16, 16) 0.0218455091794\n",
      "(16, 17) -0.15609082813\n",
      "(16, 18) 0.0995297287698\n",
      "(16, 19) -0.182817328964\n",
      "(16, 20) -0.0416986176255\n",
      "(16, 21) -0.08554700619\n",
      "(16, 22) 0.0183159287737\n",
      "(16, 23) 0.113398028523\n",
      "(16, 24) 0.0102522220491\n",
      "(16, 25) 0.180823332085\n",
      "(16, 26) 0.0318971831614\n",
      "(16, 27) 0.230713387861\n",
      "(16, 28) -0.132400537201\n",
      "(16, 29) 0.151924046055\n",
      "(17, 0) -0.0235941446824\n",
      "(17, 1) -0.329570095259\n",
      "(17, 2) 0.185600923786\n",
      "(17, 3) -0.0867112453395\n",
      "(17, 4) -0.0221398663847\n",
      "(17, 5) 0.156779828497\n",
      "(17, 6) -0.000755595008783\n",
      "(17, 7) 0.0455266002231\n",
      "(17, 8) -0.0895206477391\n",
      "(17, 9) -0.159708342018\n",
      "(17, 10) 0.181231763374\n",
      "(17, 11) 0.0877473413485\n",
      "(17, 12) 0.196696652477\n",
      "(17, 13) -0.389238503251\n",
      "(17, 14) -0.0125367848103\n",
      "(17, 15) -0.038870285568\n",
      "(17, 16) -0.0214243162766\n",
      "(17, 17) -0.112348670234\n",
      "(17, 18) 0.160364373913\n",
      "(17, 19) -0.0237889901111\n",
      "(17, 20) 0.0674465850281\n",
      "(17, 21) 0.0853501722631\n",
      "(17, 22) 0.281707865391\n",
      "(17, 23) 0.13259689946\n",
      "(17, 24) -0.188319489558\n",
      "(17, 25) -0.390062517308\n",
      "(17, 26) -0.0180428474383\n",
      "(17, 27) 0.0764068614156\n",
      "(17, 28) 0.223800855625\n",
      "(17, 29) -0.217601542385\n",
      "(18, 0) 0.0152235918094\n",
      "(18, 1) 0.108085548334\n",
      "(18, 2) -0.000723102377975\n",
      "(18, 3) -0.255325421872\n",
      "(18, 4) -0.0832829960551\n",
      "(18, 5) -0.266797564175\n",
      "(18, 6) 0.296644829501\n",
      "(18, 7) 0.00928851222604\n",
      "(18, 8) -0.0514815159836\n",
      "(18, 9) 0.0252759976949\n",
      "(18, 10) -0.121500284989\n",
      "(18, 11) -0.144900833021\n",
      "(18, 12) -0.0933044231211\n",
      "(18, 13) 0.0919556139234\n",
      "(18, 14) -0.00920374074731\n",
      "(18, 15) 0.134531210572\n",
      "(18, 16) -0.162254190794\n",
      "(18, 17) 0.00409068521279\n",
      "(18, 18) 0.134259607298\n",
      "(18, 19) -0.207711800959\n",
      "(18, 20) -0.0965400397401\n",
      "(18, 21) -0.116916099246\n",
      "(18, 22) 0.327389905941\n",
      "(18, 23) -0.165612613445\n",
      "(18, 24) -0.310656455182\n",
      "(18, 25) 0.105030364272\n",
      "(18, 26) -0.224336501464\n",
      "(18, 27) -0.322981392475\n",
      "(18, 28) -0.0486512625297\n",
      "(18, 29) -0.00296128872534\n",
      "(19, 0) 0.357962827469\n",
      "(19, 1) -0.0633179182419\n",
      "(19, 2) -0.00763437832951\n",
      "(19, 3) 0.0539855577131\n",
      "(19, 4) -0.0994020211476\n",
      "(19, 5) -0.148127924238\n",
      "(19, 6) 0.312511245948\n",
      "(19, 7) -0.128175544178\n",
      "(19, 8) -0.0360619520912\n",
      "(19, 9) -0.0725436831051\n",
      "(19, 10) 0.0181208607231\n",
      "(19, 11) -0.0781070056632\n",
      "(19, 12) 0.25558875536\n",
      "(19, 13) 0.12517638508\n",
      "(19, 14) -0.0288045959529\n",
      "(19, 15) 0.0642369240911\n",
      "(19, 16) -0.195166701067\n",
      "(19, 17) -0.136936196915\n",
      "(19, 18) -0.180439906128\n",
      "(19, 19) 0.157133212308\n",
      "(19, 20) 0.169913418047\n",
      "(19, 21) 0.207638059191\n",
      "(19, 22) -0.0763521264879\n",
      "(19, 23) -0.0252586485949\n",
      "(19, 24) -0.051637842402\n",
      "(19, 25) 0.301394987812\n",
      "(19, 26) 0.15950170682\n",
      "(19, 27) 0.0281226006926\n",
      "(19, 28) 0.0512370183614\n",
      "(19, 29) 0.0754058450791\n",
      "W2 relative error: 1.00e+00\n",
      "(0, 0) -0.475050885917\n",
      "(0, 1) 0.13244256607\n",
      "(0, 2) 0.340426592205\n",
      "(0, 3) -0.270975652894\n",
      "(0, 4) 0.0489062993214\n",
      "(0, 5) 0.149027609719\n",
      "(0, 6) -0.22343598185\n",
      "(0, 7) 0.0868226282869\n",
      "(0, 8) 0.143929756824\n",
      "(0, 9) -0.0577318859385\n",
      "(1, 0) -0.265296425495\n",
      "(1, 1) 0.109715433982\n",
      "(1, 2) 0.0655651162695\n",
      "(1, 3) -0.0296717944437\n",
      "(1, 4) 0.0670179987061\n",
      "(1, 5) -0.0453516396881\n",
      "(1, 6) 0.00300636937567\n",
      "(1, 7) -0.0262308352816\n",
      "(1, 8) 0.251739634027\n",
      "(1, 9) -0.149408253503\n",
      "(2, 0) -0.244287343421\n",
      "(2, 1) 0.0769222709973\n",
      "(2, 2) 0.131799972491\n",
      "(2, 3) 0.131562604455\n",
      "(2, 4) 0.252487064145\n",
      "(2, 5) 0.264291468266\n",
      "(2, 6) 0.0369069032669\n",
      "(2, 7) 0.0643485522644\n",
      "(2, 8) -0.0375366879801\n",
      "(2, 9) 0.259151002879\n",
      "(3, 0) -0.728606741607\n",
      "(3, 1) 0.0455888550466\n",
      "(3, 2) -0.044255818743\n",
      "(3, 3) -0.158612032841\n",
      "(3, 4) 0.170435322167\n",
      "(3, 5) 0.349237655373\n",
      "(3, 6) 0.120111346913\n",
      "(3, 7) 0.0395499387906\n",
      "(3, 8) -0.0625828158185\n",
      "(3, 9) 0.0998359289905\n",
      "(4, 0) 0.156157581932\n",
      "(4, 1) 0.04650756944\n",
      "(4, 2) -0.0333457199631\n",
      "(4, 3) -0.114212526992\n",
      "(4, 4) -0.0480907888623\n",
      "(4, 5) -0.362077111582\n",
      "(4, 6) 0.123773244098\n",
      "(4, 7) 0.018535834112\n",
      "(4, 8) 0.0232831101954\n",
      "(4, 9) 0.049846224659\n",
      "(5, 0) 0.0511093265487\n",
      "(5, 1) -0.0400711606119\n",
      "(5, 2) 0.282756452208\n",
      "(5, 3) 0.21357659965\n",
      "(5, 4) 0.0378535660595\n",
      "(5, 5) -0.358394377731\n",
      "(5, 6) -0.357297690812\n",
      "(5, 7) -0.112981491762\n",
      "(5, 8) 0.272664298961\n",
      "(5, 9) -0.192983955793\n",
      "(6, 0) -0.407486406484\n",
      "(6, 1) 0.100470704689\n",
      "(6, 2) 0.39624909931\n",
      "(6, 3) 0.0297045820385\n",
      "(6, 4) 0.0897393001686\n",
      "(6, 5) -0.0412403537542\n",
      "(6, 6) 0.0758805332346\n",
      "(6, 7) 0.259196070473\n",
      "(6, 8) 0.0293956365915\n",
      "(6, 9) 0.0370007557038\n",
      "(7, 0) -0.556301060861\n",
      "(7, 1) -0.0732039481921\n",
      "(7, 2) 0.217573057748\n",
      "(7, 3) 0.154987512646\n",
      "(7, 4) 0.272289975634\n",
      "(7, 5) 0.0419158676657\n",
      "(7, 6) 0.0145321287004\n",
      "(7, 7) -0.099621023697\n",
      "(7, 8) 0.111129348301\n",
      "(7, 9) 0.0620991690958\n",
      "(8, 0) -0.56617741242\n",
      "(8, 1) -0.156375873006\n",
      "(8, 2) 0.492142327779\n",
      "(8, 3) -0.0551428948281\n",
      "(8, 4) 0.203660663667\n",
      "(8, 5) -0.292657340495\n",
      "(8, 6) 0.130904312634\n",
      "(8, 7) -0.153648444012\n",
      "(8, 8) -0.050093568138\n",
      "(8, 9) -0.295554961127\n",
      "(9, 0) -0.371456881032\n",
      "(9, 1) -0.065840545016\n",
      "(9, 2) 0.253680104034\n",
      "(9, 3) 0.233851071085\n",
      "(9, 4) 0.423341742728\n",
      "(9, 5) -0.00522933842895\n",
      "(9, 6) 0.094839712883\n",
      "(9, 7) -0.109059303632\n",
      "(9, 8) 0.377637391535\n",
      "(9, 9) -0.0832198877809\n",
      "(10, 0) -0.578276279573\n",
      "(10, 1) 0.014616912436\n",
      "(10, 2) 0.259391409108\n",
      "(10, 3) -0.125808633733\n",
      "(10, 4) 0.0801461951916\n",
      "(10, 5) 0.293301856402\n",
      "(10, 6) -0.0536216235414\n",
      "(10, 7) 0.252023594971\n",
      "(10, 8) 0.00392628831669\n",
      "(10, 9) 0.0611994918742\n",
      "(11, 0) 0.15481409994\n",
      "(11, 1) 0.143341120307\n",
      "(11, 2) -0.0193949206473\n",
      "(11, 3) -0.08387506929\n",
      "(11, 4) 0.323033712846\n",
      "(11, 5) -0.629660495877\n",
      "(11, 6) 0.0869247806179\n",
      "(11, 7) 0.000236433717049\n",
      "(11, 8) 0.384609680637\n",
      "(11, 9) -0.0991762861613\n",
      "(12, 0) -0.0272894372877\n",
      "(12, 1) -0.0564940501935\n",
      "(12, 2) 0.19385668093\n",
      "(12, 3) -0.200234421133\n",
      "(12, 4) 0.0597237626909\n",
      "(12, 5) -0.594825030031\n",
      "(12, 6) -0.380369656128\n",
      "(12, 7) -0.0785214706145\n",
      "(12, 8) 0.295322419275\n",
      "(12, 9) -0.271310655187\n",
      "(13, 0) -0.220122359318\n",
      "(13, 1) 0.295388742533\n",
      "(13, 2) 0.316426875591\n",
      "(13, 3) 0.131702875361\n",
      "(13, 4) 0.153113627244\n",
      "(13, 5) -0.62619369614\n",
      "(13, 6) -0.0385034712114\n",
      "(13, 7) 0.225550163435\n",
      "(13, 8) 0.170817334322\n",
      "(13, 9) 0.0158202008826\n",
      "(14, 0) 0.0180288515228\n",
      "(14, 1) -0.034033098073\n",
      "(14, 2) -0.022076784667\n",
      "(14, 3) 0.137889042318\n",
      "(14, 4) 0.0235902126278\n",
      "(14, 5) -0.416649084567\n",
      "(14, 6) -0.0136852985833\n",
      "(14, 7) -0.0952718525404\n",
      "(14, 8) 0.229711500399\n",
      "(14, 9) -0.0896335083045\n",
      "(15, 0) -0.526887557939\n",
      "(15, 1) -0.00821426771047\n",
      "(15, 2) -0.279990459262\n",
      "(15, 3) -0.222106453807\n",
      "(15, 4) 0.0274954894852\n",
      "(15, 5) -0.0789719366789\n",
      "(15, 6) 0.404902624229\n",
      "(15, 7) -0.189189045052\n",
      "(15, 8) 0.175083818288\n",
      "(15, 9) -0.0311787819562\n",
      "(16, 0) -0.249453990175\n",
      "(16, 1) 0.189990233102\n",
      "(16, 2) 0.14640133128\n",
      "(16, 3) -0.331186626212\n",
      "(16, 4) -0.118265337967\n",
      "(16, 5) -0.558350063073\n",
      "(16, 6) 0.0283216252228\n",
      "(16, 7) 0.0426632602579\n",
      "(16, 8) 0.0576056725876\n",
      "(16, 9) -0.071020852177\n",
      "(17, 0) -0.43030106367\n",
      "(17, 1) 0.242507784387\n",
      "(17, 2) -0.00423817749784\n",
      "(17, 3) -0.266939426252\n",
      "(17, 4) -0.0804773835572\n",
      "(17, 5) -0.0140092418999\n",
      "(17, 6) -0.0162762190836\n",
      "(17, 7) 0.0869131824732\n",
      "(17, 8) 0.128628239349\n",
      "(17, 9) -0.0388323141198\n",
      "(18, 0) -0.471294035354\n",
      "(18, 1) 5.7652638219e-05\n",
      "(18, 2) -0.0786660579344\n",
      "(18, 3) 0.0526593069594\n",
      "(18, 4) 0.072039606458\n",
      "(18, 5) 0.198920259065\n",
      "(18, 6) 0.194658995634\n",
      "(18, 7) -0.193014803163\n",
      "(18, 8) -0.136219419788\n",
      "(18, 9) 0.0328614640388\n",
      "(19, 0) -0.554665437003\n",
      "(19, 1) 0.155174460748\n",
      "(19, 2) -0.0244747308642\n",
      "(19, 3) 0.168667760647\n",
      "(19, 4) -0.0278868368842\n",
      "(19, 5) -0.00110106972429\n",
      "(19, 6) -0.122558445392\n",
      "(19, 7) -0.502137942915\n",
      "(19, 8) 0.10203346994\n",
      "(19, 9) 0.0449738846164\n",
      "(20, 0) -0.0884000714407\n",
      "(20, 1) -0.0848326884739\n",
      "(20, 2) 0.0194364176309\n",
      "(20, 3) 0.245865666804\n",
      "(20, 4) -0.0542259532388\n",
      "(20, 5) -0.233813713191\n",
      "(20, 6) -0.129670694671\n",
      "(20, 7) 0.166214671093\n",
      "(20, 8) 0.251638793269\n",
      "(20, 9) 0.0984078554644\n",
      "(21, 0) 0.102009759217\n",
      "(21, 1) -0.254524994725\n",
      "(21, 2) -0.253436180708\n",
      "(21, 3) 0.13673449808\n",
      "(21, 4) -0.0508937828769\n",
      "(21, 5) -0.0609797128792\n",
      "(21, 6) 0.0611340270851\n",
      "(21, 7) -0.083748288926\n",
      "(21, 8) 0.0638629275684\n",
      "(21, 9) -0.0683492264564\n",
      "(22, 0) -0.555056467944\n",
      "(22, 1) -0.0254813960154\n",
      "(22, 2) 0.0494210104396\n",
      "(22, 3) 0.162777526924\n",
      "(22, 4) 0.180564583818\n",
      "(22, 5) 0.262106764737\n",
      "(22, 6) 0.129373740032\n",
      "(22, 7) -0.20423526621\n",
      "(22, 8) -0.0371814793176\n",
      "(22, 9) -0.0444142206124\n",
      "(23, 0) -0.0016046461937\n",
      "(23, 1) 0.241950327284\n",
      "(23, 2) -0.104781931753\n",
      "(23, 3) -0.120465903031\n",
      "(23, 4) 0.286177015063\n",
      "(23, 5) -0.470896281568\n",
      "(23, 6) -0.0311679369425\n",
      "(23, 7) -0.0701985897411\n",
      "(23, 8) 0.119929418219\n",
      "(23, 9) 0.0787578005479\n",
      "(24, 0) 0.0654224852514\n",
      "(24, 1) 0.0169291374696\n",
      "(24, 2) 0.135404742752\n",
      "(24, 3) 0.147514932403\n",
      "(24, 4) 0.132572167111\n",
      "(24, 5) -0.344015233988\n",
      "(24, 6) 0.148897722951\n",
      "(24, 7) -0.272749133456\n",
      "(24, 8) -0.13901905036\n",
      "(24, 9) 0.352879038878\n",
      "(25, 0) -0.455144689848\n",
      "(25, 1) -0.125209817936\n",
      "(25, 2) 0.193038999718\n",
      "(25, 3) -0.120483461963\n",
      "(25, 4) 0.164824494053\n",
      "(25, 5) -0.343691518356\n",
      "(25, 6) -0.174154056598\n",
      "(25, 7) 0.11307006762\n",
      "(25, 8) -0.0403347969247\n",
      "(25, 9) 0.281505744493\n",
      "(26, 0) -0.077401704246\n",
      "(26, 1) 0.0655235117275\n",
      "(26, 2) 0.0526269982259\n",
      "(26, 3) -0.111614612264\n",
      "(26, 4) 0.165851117373\n",
      "(26, 5) -0.276424863532\n",
      "(26, 6) -0.109575305096\n",
      "(26, 7) -0.0963933379783\n",
      "(26, 8) 0.201409304967\n",
      "(26, 9) -0.0800216557462\n",
      "(27, 0) 0.0914971323596\n",
      "(27, 1) 0.336884713592\n",
      "(27, 2) 0.0470926951213\n",
      "(27, 3) 0.482111781785\n",
      "(27, 4) 0.117317703818\n",
      "(27, 5) -0.575295348604\n",
      "(27, 6) -0.106845634562\n",
      "(27, 7) 0.147268521511\n",
      "(27, 8) -0.0245745140681\n",
      "(27, 9) 0.146446051819\n",
      "(28, 0) -0.215033111495\n",
      "(28, 1) -0.234685553435\n",
      "(28, 2) 0.206202936859\n",
      "(28, 3) 0.244568773811\n",
      "(28, 4) 0.0323711756067\n",
      "(28, 5) -0.541797958942\n",
      "(28, 6) 0.162822533945\n",
      "(28, 7) -0.211482403056\n",
      "(28, 8) 0.177706112581\n",
      "(28, 9) 0.0311006157716\n",
      "(29, 0) -0.0030211542601\n",
      "(29, 1) -0.11211249813\n",
      "(29, 2) -0.036700296091\n",
      "(29, 3) 0.133751874465\n",
      "(29, 4) 0.000949148493135\n",
      "(29, 5) -0.109133706072\n",
      "(29, 6) -0.0662199379331\n",
      "(29, 7) -0.10659812002\n",
      "(29, 8) 0.0115735964812\n",
      "(29, 9) -0.00339164882845\n",
      "W3 relative error: 5.57e-07\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "b1 relative error: 2.22e-08\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "(20,) 0.0\n",
      "(21,) 0.0\n",
      "(22,) 0.0\n",
      "(23,) 0.0\n",
      "(24,) 0.0\n",
      "(25,) 0.0\n",
      "(26,) 0.0\n",
      "(27,) 0.0\n",
      "(28,) 0.0\n",
      "(29,) 0.0\n",
      "b2 relative error: 7.99e-07\n",
      "(0,) -0.414700731266\n",
      "(1,) 0.0954908379036\n",
      "(2,) 0.122919489876\n",
      "(3,) 0.0923552072152\n",
      "(4,) 0.124355788778\n",
      "(5,) -0.3892923786\n",
      "(6,) 0.0851203703967\n",
      "(7,) 0.0727791891642\n",
      "(8,) 0.125729864653\n",
      "(9,) 0.0852423618802\n",
      "b3 relative error: 3.49e-10\n"
     ]
    }
   ],
   "source": [
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print 'Running check with reg = ', reg\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64,\n",
    "                            use_batchnorm=True)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print 'Initial loss: ', loss\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print '%s relative error: %.2e' % (name, rel_error(grad_num, grads[name]))\n",
    "  if reg == 0: print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm for deep networks\n",
    "Run the following to train a six-layer network on a subset of 1000 training examples both with and without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try training a very deep net with batchnorm\n",
    "hidden_dims = [100, 100, 100, 100, 100]\n",
    "\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 2e-2\n",
    "bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, use_batchnorm=True)\n",
    "model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, use_batchnorm=False)\n",
    "\n",
    "bn_solver = Solver(bn_model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=200)\n",
    "bn_solver.train()\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=200)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to visualize the results from two networks trained above. You should find that using batch normalization helps the network to converge much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o', label='baseline')\n",
    "plt.plot(bn_solver.loss_history, 'o', label='batchnorm')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o', label='baseline')\n",
    "plt.plot(bn_solver.train_acc_history, '-o', label='batchnorm')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(solver.val_acc_history, '-o', label='baseline')\n",
    "plt.plot(bn_solver.val_acc_history, '-o', label='batchnorm')\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization and initialization\n",
    "We will now run a small experiment to study the interaction of batch normalization and weight initialization.\n",
    "\n",
    "The first cell will train 8-layer networks both with and without batch normalization using different scales for weight initialization. The second layer will plot training accuracy, validation set accuracy, and training loss as a function of the weight initialization scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try training a very deep net with batchnorm\n",
    "hidden_dims = [50, 50, 50, 50, 50, 50, 50]\n",
    "\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "bn_solvers = {}\n",
    "solvers = {}\n",
    "weight_scales = np.logspace(-4, 0, num=20)\n",
    "for i, weight_scale in enumerate(weight_scales):\n",
    "  print 'Running weight scale %d / %d' % (i + 1, len(weight_scales))\n",
    "  bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, use_batchnorm=True)\n",
    "  model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, use_batchnorm=False)\n",
    "\n",
    "  bn_solver = Solver(bn_model, small_data,\n",
    "                  num_epochs=10, batch_size=50,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                  },\n",
    "                  verbose=False, print_every=200)\n",
    "  bn_solver.train()\n",
    "  bn_solvers[weight_scale] = bn_solver\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=10, batch_size=50,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                  },\n",
    "                  verbose=False, print_every=200)\n",
    "  solver.train()\n",
    "  solvers[weight_scale] = solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot results of weight scale experiment\n",
    "best_train_accs, bn_best_train_accs = [], []\n",
    "best_val_accs, bn_best_val_accs = [], []\n",
    "final_train_loss, bn_final_train_loss = [], []\n",
    "\n",
    "for ws in weight_scales:\n",
    "  best_train_accs.append(max(solvers[ws].train_acc_history))\n",
    "  bn_best_train_accs.append(max(bn_solvers[ws].train_acc_history))\n",
    "  \n",
    "  best_val_accs.append(max(solvers[ws].val_acc_history))\n",
    "  bn_best_val_accs.append(max(bn_solvers[ws].val_acc_history))\n",
    "  \n",
    "  final_train_loss.append(np.mean(solvers[ws].loss_history[-100:]))\n",
    "  bn_final_train_loss.append(np.mean(bn_solvers[ws].loss_history[-100:]))\n",
    "  \n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Best val accuracy vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Best val accuracy')\n",
    "plt.semilogx(weight_scales, best_val_accs, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales, bn_best_val_accs, '-o', label='batchnorm')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Best train accuracy vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Best training accuracy')\n",
    "plt.semilogx(weight_scales, best_train_accs, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales, bn_best_train_accs, '-o', label='batchnorm')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Final training loss vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Final training loss')\n",
    "plt.semilogx(weight_scales, final_train_loss, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales, bn_final_train_loss, '-o', label='batchnorm')\n",
    "plt.legend()\n",
    "\n",
    "plt.gcf().set_size_inches(10, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:\n",
    "Describe the results of this experiment, and try to give a reason why the experiment gave the results that it did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
